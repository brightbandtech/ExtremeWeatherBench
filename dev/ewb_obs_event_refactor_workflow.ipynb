{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, List, Optional, Union\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dacite\n",
    "from scores.continuous import mae, rmse\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from extremeweatherbench import case, metrics, observations,utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DerivedVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DerivedVariable(ABC):\n",
    "    \"\"\"A base class defining the interface for ExtremeWeatherBench derived variables.\n",
    "    \n",
    "    A DerivedVariable is any variable that requires extra computation, not derived in an\n",
    "    observation or forecast raw dataset. Some examples include the practically perfect hindcast,\n",
    "    MLCAPE, IVT, or atmospheric river masks.\n",
    "    \n",
    "    Attributes:\n",
    "        name: The name of the variable.\n",
    "        input_variables: A list of variables that are used to compute the variable.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, input_variables: List[str]):\n",
    "        self.name = name\n",
    "        self.input_variables = input_variables\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute(self, data: xr.Dataset) -> xr.Dataset:\n",
    "        \"\"\"Compute the variable from the input variables.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'extremeweatherbench.case' has no attribute 'CaseOperator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# type hint for the data input to the observation classes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ObservationDataInput \u001b[38;5;241m=\u001b[39m Union[\n\u001b[1;32m      3\u001b[0m     xr\u001b[38;5;241m.\u001b[39mDataset, xr\u001b[38;5;241m.\u001b[39mDataArray, pl\u001b[38;5;241m.\u001b[39mLazyFrame, pd\u001b[38;5;241m.\u001b[39mDataFrame, np\u001b[38;5;241m.\u001b[39mndarray\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43;01mObservation\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mABC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43;03m    Abstract base class for all observation types.\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43;03m    same coordinate system for evaluation.\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43m@abstractmethod\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;21;43m_open_data_from_source\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mObservationDataInput\u001b[49m\u001b[43m:\u001b[49m\n",
      "Cell \u001b[0;32mIn[63], line 92\u001b[0m, in \u001b[0;36mObservation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m             data[v\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m derived_variable\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_pipeline\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m---> 92\u001b[0m     case: \u001b[43mcase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCaseOperator\u001b[49m,\n\u001b[1;32m     93\u001b[0m     storage_options: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset:\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Shared method for running the observation pipeline.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m        The observation data with a type determined by the user.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# Open data and process through pipeline steps\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'extremeweatherbench.case' has no attribute 'CaseOperator'"
     ]
    }
   ],
   "source": [
    "# type hint for the data input to the observation classes\n",
    "ObservationDataInput = Union[\n",
    "    xr.Dataset, xr.DataArray, pl.LazyFrame, pd.DataFrame, np.ndarray\n",
    "]\n",
    "\n",
    "class Observation(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all observation types.\n",
    "\n",
    "    An Observation is data that acts as the \"truth\" for a case. It can be a gridded dataset,\n",
    "    a point observation dataset, or any other reference dataset. Observations in EWB\n",
    "    are not required to be the same variable as the forecast dataset, but they must be in the\n",
    "    same coordinate system for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _open_data_from_source(\n",
    "        self, source: str, storage_options: Optional[dict] = None\n",
    "    ) -> ObservationDataInput:\n",
    "        \"\"\"\n",
    "        Open the observation data from the source, opting to avoid loading the entire dataset into memory if possible.\n",
    "\n",
    "        Args:\n",
    "            source: The source of the observation data, which can be a local path or a remote URL.\n",
    "            storage_options: Optional storage options for the source if the source is a remote URL.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with a type determined by the user.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        data: ObservationDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        variables: Optional[list[str]] = None,\n",
    "    ) -> ObservationDataInput:\n",
    "        \"\"\"\n",
    "        Subset the observation data to the case information provided in IndividualCase.\n",
    "\n",
    "        Time information, spatial bounds, and variables are captured in the case metadata\n",
    "        where this method is used to subset.\n",
    "\n",
    "        Args:\n",
    "            data: The observation data to subset, which should be a xarray dataset, xarray dataarray, polars lazyframe,\n",
    "            pandas dataframe, or numpy array.\n",
    "            variables: The variables to include in the observation. Some observations may not have variables, or\n",
    "            only have a singular variable; thus, this is optional.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with the variables subset to the case metadata.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _maybe_convert_to_dataset(self, data: ObservationDataInput) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Convert the observation data to an xarray dataset if it is not already.\n",
    "\n",
    "        If this method is used prior to _subset_data_to_case, OOM errors are possible\n",
    "        prior to subsetting.\n",
    "\n",
    "        Args:\n",
    "            data: The observation data already run through _subset_data_to_case.\n",
    "\n",
    "        Returns:\n",
    "            The observation data as an xarray dataset.\n",
    "        \"\"\"\n",
    "\n",
    "    def _maybe_derive_variables(\n",
    "        self, data: xr.Dataset, variables: list[str | DerivedVariable]\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Derive variables from the observation data if any exist in variables.\n",
    "\n",
    "        Args:\n",
    "            data: The observation data already run through _subset_data_to_case.\n",
    "            variables: The variables to derive.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with the derived variables.\n",
    "        \"\"\"\n",
    "\n",
    "        for v in variables:\n",
    "            if isinstance(v, DerivedVariable):\n",
    "                derived_variable = v.compute(data)\n",
    "                data[v.name] = derived_variable\n",
    "        return data\n",
    "\n",
    "    def run_pipeline(\n",
    "        self,\n",
    "        source: str,\n",
    "        case: case.CaseOperator,\n",
    "        storage_options: Optional[dict] = None,\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Shared method for running the observation pipeline.\n",
    "\n",
    "        Args:\n",
    "            source: The source of the observation data, which can be a local path or a remote URL.\n",
    "            storage_options: Optional storage options for the source if the source is a remote URL.\n",
    "            variables: The variables to include in the observation. Some observations may not have variables, or\n",
    "            only have a singular variable; thus, this is optional.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with a type determined by the user.\n",
    "        \"\"\"\n",
    "\n",
    "        # Open data and process through pipeline steps\n",
    "        data = (\n",
    "            self._open_data_from_source(\n",
    "                source=source,\n",
    "                storage_options=storage_options,\n",
    "            )\n",
    "            .pipe(\n",
    "                self._subset_data_to_case,\n",
    "                case=case,\n",
    "                variables=[v for v in case.variables if isinstance(v, str)],\n",
    "            )\n",
    "            .pipe(self._maybe_convert_to_dataset)\n",
    "            .pipe(self._maybe_derive_variables, variables=case.variables)\n",
    "        )\n",
    "        return data\n",
    "\n",
    "\n",
    "class ERA5(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for ERA5 gridded data.\n",
    "\n",
    "    The easiest approach to using this class\n",
    "    is to use the ARCO ERA5 dataset provided by Google for a source. Otherwise, either a\n",
    "    different zarr source or modifying the _open_data_from_source method to open the data\n",
    "    using another method is required.\n",
    "    \"\"\"\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, source: str, storage_options: Optional[dict] = None\n",
    "    ) -> ObservationDataInput:\n",
    "        data = xr.open_zarr(\n",
    "            source,\n",
    "            chunks=None,\n",
    "            storage_options=dict(token=\"anon\"),\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        data: ObservationDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        variables: Optional[list[str]] = None,\n",
    "    ) -> ObservationDataInput:\n",
    "        # TODO: fix case to automatically apply these; currently stand-in for now\n",
    "        case.latitude_min = case.location.latitude - case.bounding_box_degrees / 2\n",
    "        case.latitude_max = case.location.latitude + case.bounding_box_degrees / 2\n",
    "        case.longitude_min = np.mod(\n",
    "            case.location.longitude - case.bounding_box_degrees / 2, 360\n",
    "        )\n",
    "        case.longitude_max = np.mod(\n",
    "            case.location.longitude + case.bounding_box_degrees / 2, 360\n",
    "        )\n",
    "\n",
    "        if not isinstance(data, (xr.Dataset, xr.DataArray)):\n",
    "            raise ValueError(f\"Expected xarray Dataset or DataArray, got {type(data)}\")\n",
    "\n",
    "        subset_data = data.sel(\n",
    "            time=slice(case.start_date, case.end_date),\n",
    "            # latitudes are sliced from max to min\n",
    "            latitude=slice(case.latitude_max, case.latitude_min),\n",
    "            longitude=slice(case.longitude_min, case.longitude_max),\n",
    "        )\n",
    "\n",
    "        # check that the variables are in the observation data\n",
    "        if variables is not None and any(\n",
    "            var not in subset_data.data_vars for var in variables\n",
    "        ):\n",
    "            raise ValueError(f\"Variables {variables} not found in observation data\")\n",
    "\n",
    "        # subset the variables\n",
    "        if variables is not None:\n",
    "            subset_data = subset_data[variables]\n",
    "\n",
    "        return subset_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: ObservationDataInput):\n",
    "        if isinstance(data, xr.DataArray):\n",
    "            data = data.to_dataset()\n",
    "        return data\n",
    "\n",
    "\n",
    "class GHCN(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for GHCN tabular data.\n",
    "\n",
    "    Data is processed using polars to maintain the lazy loading\n",
    "    paradigm in _open_data_from_source and to separate the subsetting\n",
    "    into _subset_data_to_case.\n",
    "    \"\"\"\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, source: str, storage_options: Optional[dict] = None\n",
    "    ) -> ObservationDataInput:\n",
    "        observation_data: pl.LazyFrame = pl.scan_parquet(\n",
    "            source, storage_options=storage_options\n",
    "        )\n",
    "\n",
    "        return observation_data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        observation_data: ObservationDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        variables: Optional[list[str]] = None,\n",
    "    ) -> ObservationDataInput:\n",
    "        # Create filter expressions for LazyFrame\n",
    "        time_min = case.start_date - pd.Timedelta(days=2)\n",
    "        time_max = case.end_date + pd.Timedelta(days=2)\n",
    "\n",
    "        # TODO: fix case to automatically apply these; currently stand-in for now\n",
    "        case.latitude_min = case.location.latitude - case.bounding_box_degrees / 2\n",
    "        case.latitude_max = case.location.latitude + case.bounding_box_degrees / 2\n",
    "        case.longitude_min = case.location.longitude - case.bounding_box_degrees / 2\n",
    "        case.longitude_max = case.location.longitude + case.bounding_box_degrees / 2\n",
    "\n",
    "        if not isinstance(observation_data, pl.LazyFrame):\n",
    "            raise ValueError(f\"Expected polars LazyFrame, got {type(observation_data)}\")\n",
    "\n",
    "        # Apply filters using proper polars expressions\n",
    "        subset_observation_data = observation_data.filter(\n",
    "            (pl.col(\"time\") >= time_min)\n",
    "            & (pl.col(\"time\") <= time_max)\n",
    "            & (pl.col(\"latitude\") >= case.latitude_min)\n",
    "            & (pl.col(\"latitude\") <= case.latitude_max)\n",
    "            & (pl.col(\"longitude\") >= case.longitude_min)\n",
    "            & (pl.col(\"longitude\") <= case.longitude_max)\n",
    "        )\n",
    "\n",
    "        # Add time, latitude, and longitude to the variables, polars doesn't do indexes\n",
    "        if variables is None:\n",
    "            all_variables = [\"time\", \"latitude\", \"longitude\"]\n",
    "        else:\n",
    "            all_variables = variables + [\"time\", \"latitude\", \"longitude\"]\n",
    "\n",
    "        # check that the variables are in the observation data\n",
    "        schema_fields = [field for field in subset_observation_data.collect_schema()]\n",
    "        if variables is not None and any(\n",
    "            var not in schema_fields for var in all_variables\n",
    "        ):\n",
    "            raise ValueError(f\"Variables {all_variables} not found in observation data\")\n",
    "\n",
    "        # subset the variables\n",
    "        if variables is not None:\n",
    "            subset_observation_data = subset_observation_data.select(all_variables)\n",
    "\n",
    "        return subset_observation_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: ObservationDataInput):\n",
    "        if isinstance(data, pl.LazyFrame):\n",
    "            data = data.collect().to_pandas()\n",
    "            data = data.set_index([\"time\", \"latitude\", \"longitude\"])\n",
    "            # GHCN data can have duplicate values right now, dropping here if it occurs\n",
    "            try:\n",
    "                data = data.to_xarray()\n",
    "            except ValueError as e:\n",
    "                if \"non-unique\" in str(e):\n",
    "                    logger.warning(\n",
    "                        \"ValueError when converting to xarray due to duplicate indexes\"\n",
    "                    )\n",
    "                data = data.drop_duplicates().to_xarray()\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Data is not a polars LazyFrame: {type(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO implement this in case.py\n",
    "@dataclasses.dataclass\n",
    "class BaseCaseMetadataCollection:\n",
    "    cases: List[case.IndividualCase]\n",
    "\n",
    "    def subset_cases_by_event_type(self, event_type: str) -> List[case.IndividualCase]:\n",
    "        \"\"\"Subset the cases in the collection by event type.\"\"\"\n",
    "        return [c for c in self.cases if c.event_type == event_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class CaseOperator:\n",
    "    \"\"\"A class which stores the graph to process an individual case.\"\"\"\n",
    "    \n",
    "    case: case.IndividualCase\n",
    "    metrics: list[metrics.Metric]\n",
    "    observations: list[observations.Observation]\n",
    "    variable_mapping: dict[str | DerivedVariable, str | DerivedVariable] = None\n",
    "    \n",
    "    def evaluate_case(self, forecast: xr.Dataset):\n",
    "        \"\"\"Process a case.\"\"\"\n",
    "        self.process_metrics(forecast)\n",
    "        \n",
    "    def process_metrics(self, forecast: xr.Dataset):\n",
    "        \"\"\"Process the metrics.\"\"\"\n",
    "        for metric in self.metrics:\n",
    "            metric.process_metric(forecast, self.observations)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventType(ABC):\n",
    "    \"\"\"A base class defining the interface for ExtremeWeatherBench event types.\n",
    "\n",
    "    An Event in ExtremeWeatherBench defines a specific weather event type, such as a heat wave,\n",
    "    severe convective weather, or atmospheric rivers. These events encapsulate a set of cases and\n",
    "    derived behavior for evaluating those cases. These cases will share common metrics, observations,\n",
    "    and variables while each having unique dates and locations.\n",
    "\n",
    "    Attributes:\n",
    "        case_metadata: A dictionary or yaml file with guiding metadata.\n",
    "        metrics: A list of Metrics that are used to evaluate the cases.\n",
    "        observations: A list of Observations that are used as targets for the metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        event_type: str,\n",
    "        case_metadata: dict[str, Any],\n",
    "        metrics: List[metrics.Metric],\n",
    "        observations: List[observations.Observation],\n",
    "        variable_mapping: Optional[\n",
    "            dict[str | DerivedVariable, str | DerivedVariable]\n",
    "        ] = None,\n",
    "    ):\n",
    "        self.event_type = event_type\n",
    "        self.case_metadata = case_metadata\n",
    "        self.metrics = metrics\n",
    "        self.observations = observations\n",
    "        self.variable_mapping = variable_mapping\n",
    "\n",
    "    def _build_base_case_metadata_collection(self) -> BaseCaseMetadataCollection:\n",
    "        \"\"\"Build a list of IndividualCases from the case_metadata.\"\"\"\n",
    "        cases = dacite.from_dict(\n",
    "            data_class=BaseCaseMetadataCollection, data=self.case_metadata\n",
    "        )\n",
    "        cases = BaseCaseMetadataCollection(cases=[c for c in cases.cases if c.event_type == self.event_type])\n",
    "        return cases\n",
    "    \n",
    "    def build_case_operator(self) -> list[CaseOperator]:\n",
    "        \"\"\"Build a CaseOperator from the event type.\"\"\"\n",
    "        case_metadata_collection = self._build_base_case_metadata_collection()\n",
    "        case_operators = [\n",
    "            CaseOperator(\n",
    "                case = case,\n",
    "                metrics = self.metrics,\n",
    "                observations = self.observations,\n",
    "                variable_mapping = self.variable_mapping\n",
    "                ) \n",
    "                for case in case_metadata_collection.cases\n",
    "                ]\n",
    "        return case_operators\n",
    "    \n",
    "\n",
    "class HeatWave(EventType):\n",
    "    def __init__(self, case_metadata: dict[str, Any], \n",
    "                 metrics: List[metrics.Metric], \n",
    "                 observations: List[Observation],\n",
    "                 variable_mapping: Optional[dict[str | DerivedVariable, str | DerivedVariable]] = None):\n",
    "        super().__init__(event_type='heat_wave', \n",
    "                         case_metadata=case_metadata, \n",
    "                         metrics=metrics, \n",
    "                         observations=observations, \n",
    "                         variable_mapping=variable_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMetric(ABC):\n",
    "    @abstractmethod\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        pass\n",
    "\n",
    "class AppliedMetric(ABC):\n",
    "    def __init__(\n",
    "            self, \n",
    "            metric: BaseMetric, \n",
    "            observation_sources: list[Observation],\n",
    "            ):\n",
    "        self.metric = metric\n",
    "        self.observation_sources = observation_sources\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset):\n",
    "        return self.metric.compute(forecast, self.observation_sources)\n",
    "\n",
    "\n",
    "class MAE(BaseMetric):\n",
    "\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return mae(forecast, observation, **kwargs)\n",
    "\n",
    "class RMSE(BaseMetric):\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return rmse(forecast, observation, **kwargs)\n",
    "\n",
    "class MaximumMAE(AppliedMetric):\n",
    "\n",
    "    def __init__(self, metric: BaseMetric = MAE, observation: Observation = ERA5):\n",
    "        super().__init__(metric, observation)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        maximum_timestep = observation.mean([\"latitude\", \"longitude\"]).idxmax(\"valid_time\").values\n",
    "        maximum_value = observation.mean([\"latitude\", \"longitude\"]).sel(valid_time=maximum_timestep).values\n",
    "        forecast_spatial_mean = forecast.mean([\"latitude\", \"longitude\"])\n",
    "        filtered_max_forecast = forecast_spatial_mean.mean(['latitude','longitude']).where(\n",
    "            (forecast_spatial_mean.valid_time >= maximum_timestep - np.timedelta64(48, 'h')) & \n",
    "            (forecast_spatial_mean.valid_time <= maximum_timestep + np.timedelta64(48, 'h')),\n",
    "            drop=True\n",
    "        ).max('valid_time')\n",
    "        return self.metric().compute(filtered_max_forecast, maximum_value)\n",
    "    \n",
    "class RegionalRMSE(AppliedMetric):\n",
    "    def __init__(self, metric: BaseMetric = RMSE, observation: Observation = ERA5):\n",
    "        super().__init__(metric, observation)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        return self.metric.compute(forecast, observation, preserve_dims='lead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaseCollection(cases=[IndividualCase(case_id_number=1, title='2021 Pacific Northwest', start_date=datetime.datetime(2021, 6, 20, 0, 0), end_date=datetime.datetime(2021, 7, 3, 0, 0), location=Location(latitude=47.6062, longitude=np.float64(237.6679)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=2, title='2022 Upper Midwest', start_date=datetime.datetime(2022, 5, 7, 0, 0), end_date=datetime.datetime(2022, 5, 17, 0, 0), location=Location(latitude=41.8781, longitude=np.float64(272.3702)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=3, title='2022 California', start_date=datetime.datetime(2022, 6, 7, 0, 0), end_date=datetime.datetime(2022, 6, 15, 0, 0), location=Location(latitude=34.0522, longitude=np.float64(241.7563)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=4, title='2022 Texas', start_date=datetime.datetime(2022, 6, 30, 0, 0), end_date=datetime.datetime(2022, 7, 18, 0, 0), location=Location(latitude=32.7767, longitude=np.float64(263.203)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=5, title='2023 Pacific Northwest', start_date=datetime.datetime(2023, 5, 10, 0, 0), end_date=datetime.datetime(2023, 5, 23, 0, 0), location=Location(latitude=47.6062, longitude=np.float64(237.6679)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=6, title='2022 Mid-Atlantic', start_date=datetime.datetime(2022, 5, 17, 0, 0), end_date=datetime.datetime(2022, 5, 24, 0, 0), location=Location(latitude=39.2904, longitude=np.float64(283.38779999999997)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=7, title='2023 Australia', start_date=datetime.datetime(2023, 11, 18, 0, 0), end_date=datetime.datetime(2023, 11, 28, 0, 0), location=Location(latitude=-31.9505, longitude=np.float64(115.8605)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=8, title='2023 Ireland', start_date=datetime.datetime(2023, 9, 2, 0, 0), end_date=datetime.datetime(2023, 9, 13, 0, 0), location=Location(latitude=53.1424, longitude=np.float64(352.3079)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=9, title='2023 Italy', start_date=datetime.datetime(2023, 7, 7, 0, 0), end_date=datetime.datetime(2023, 7, 27, 0, 0), location=Location(latitude=41.9028, longitude=np.float64(12.4964)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=10, title='2023 SW Europe', start_date=datetime.datetime(2023, 8, 17, 0, 0), end_date=datetime.datetime(2023, 8, 28, 0, 0), location=Location(latitude=40.4637, longitude=np.float64(356.2508)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=11, title='2023 South America', start_date=datetime.datetime(2023, 7, 29, 0, 0), end_date=datetime.datetime(2023, 8, 4, 0, 0), location=Location(latitude=-34.6037, longitude=np.float64(301.6184)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=12, title='2023 China (Shanghai)', start_date=datetime.datetime(2023, 5, 24, 0, 0), end_date=datetime.datetime(2023, 6, 1, 0, 0), location=Location(latitude=31.2304, longitude=np.float64(121.4737)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=13, title='2023 China (Yunnan Province)', start_date=datetime.datetime(2023, 4, 14, 0, 0), end_date=datetime.datetime(2023, 4, 23, 0, 0), location=Location(latitude=25.0458, longitude=np.float64(102.71)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=14, title='2023 Algeria', start_date=datetime.datetime(2023, 7, 5, 0, 0), end_date=datetime.datetime(2023, 7, 27, 0, 0), location=Location(latitude=36.7372, longitude=np.float64(3.0869)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=15, title='2023 Iberian Peninsula', start_date=datetime.datetime(2023, 4, 22, 0, 0), end_date=datetime.datetime(2023, 5, 1, 0, 0), location=Location(latitude=41.1496, longitude=np.float64(352.389)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=16, title='2023 Gibraltar', start_date=datetime.datetime(2023, 4, 22, 0, 0), end_date=datetime.datetime(2023, 5, 3, 0, 0), location=Location(latitude=36.1408, longitude=np.float64(354.64639999999997)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=17, title='2023 India', start_date=datetime.datetime(2023, 2, 15, 0, 0), end_date=datetime.datetime(2023, 3, 1, 0, 0), location=Location(latitude=28.6139, longitude=np.float64(77.209)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=18, title='2021 Western Russia', start_date=datetime.datetime(2021, 6, 18, 0, 0), end_date=datetime.datetime(2021, 6, 30, 0, 0), location=Location(latitude=55.7558, longitude=np.float64(37.6173)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=19, title='2022 Germany', start_date=datetime.datetime(2022, 12, 23, 0, 0), end_date=datetime.datetime(2022, 12, 31, 0, 0), location=Location(latitude=52.52, longitude=np.float64(13.405)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=20, title='2022 UK (August)', start_date=datetime.datetime(2022, 8, 8, 0, 0), end_date=datetime.datetime(2022, 8, 16, 0, 0), location=Location(latitude=51.5074, longitude=np.float64(359.8722)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=21, title='2022 UK (July)', start_date=datetime.datetime(2022, 7, 15, 0, 0), end_date=datetime.datetime(2022, 7, 23, 0, 0), location=Location(latitude=51.5074, longitude=np.float64(359.8722)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=22, title='2022 France', start_date=datetime.datetime(2022, 6, 9, 0, 0), end_date=datetime.datetime(2022, 6, 21, 0, 0), location=Location(latitude=43.4832, longitude=np.float64(358.4414)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=23, title='2022 Japan', start_date=datetime.datetime(2022, 6, 20, 0, 0), end_date=datetime.datetime(2022, 7, 5, 0, 0), location=Location(latitude=35.6895, longitude=np.float64(139.6917)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=24, title='2022 India', start_date=datetime.datetime(2022, 4, 24, 0, 0), end_date=datetime.datetime(2022, 5, 4, 0, 0), location=Location(latitude=28.2769, longitude=np.float64(68.4376)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=25, title='2022 East Antarctica', start_date=datetime.datetime(2022, 3, 12, 0, 0), end_date=datetime.datetime(2022, 3, 26, 0, 0), location=Location(latitude=-75.1, longitude=np.float64(123.35)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=26, title='2022 West Australia', start_date=datetime.datetime(2022, 1, 15, 0, 0), end_date=datetime.datetime(2022, 1, 25, 0, 0), location=Location(latitude=-31.9505, longitude=np.float64(115.8605)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=27, title='2021 Canada Plains', start_date=datetime.datetime(2021, 5, 30, 0, 0), end_date=datetime.datetime(2021, 6, 9, 0, 0), location=Location(latitude=49.0, longitude=np.float64(262.43330000000003)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=28, title='2021 New Zealand', start_date=datetime.datetime(2021, 1, 12, 18, 0), end_date=datetime.datetime(2021, 1, 17, 18, 0), location=Location(latitude=-43.8983, longitude=np.float64(171.731)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=29, title='2020 Australia', start_date=datetime.datetime(2020, 11, 25, 0, 0), end_date=datetime.datetime(2020, 11, 30, 0, 0), location=Location(latitude=-33.8245, longitude=np.float64(150.9448)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=72, title='May 2024 Texas', start_date=datetime.datetime(2024, 5, 25, 0, 0), end_date=datetime.datetime(2024, 5, 28, 0, 0), location=Location(latitude=25.9017, longitude=np.float64(262.50260000000003)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=73, title='June 2024 Northeast US', start_date=datetime.datetime(2024, 6, 17, 0, 0), end_date=datetime.datetime(2024, 6, 22, 0, 0), location=Location(latitude=41.8781, longitude=np.float64(286.771)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=74, title='July 2024 Southwest US', start_date=datetime.datetime(2024, 7, 4, 0, 0), end_date=datetime.datetime(2024, 7, 8, 0, 0), location=Location(latitude=33.7701, longitude=np.float64(243.78539999999998)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=75, title='July 2024 Northeast US', start_date=datetime.datetime(2024, 7, 7, 0, 0), end_date=datetime.datetime(2024, 7, 10, 0, 0), location=Location(latitude=40.7128, longitude=np.float64(285.994)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=76, title='July 2024 Mid-Atlantic US', start_date=datetime.datetime(2024, 7, 15, 0, 0), end_date=datetime.datetime(2024, 7, 20, 0, 0), location=Location(latitude=39.9526, longitude=np.float64(284.8348)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=77, title='August 2024 Midwest US', start_date=datetime.datetime(2024, 8, 25, 0, 0), end_date=datetime.datetime(2024, 8, 31, 0, 0), location=Location(latitude=40.1106, longitude=np.float64(271.79269999999997)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=78, title='July 2024 Antarctica', start_date=datetime.datetime(2024, 7, 1, 0, 0), end_date=datetime.datetime(2024, 7, 31, 0, 0), location=Location(latitude=-75.0, longitude=np.float64(15.0)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=79, title='August 2024 Canada', start_date=datetime.datetime(2024, 8, 9, 0, 0), end_date=datetime.datetime(2024, 8, 11, 0, 0), location=Location(latitude=67.0, longitude=np.float64(248.0)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=80, title='August 2024 Australia', start_date=datetime.datetime(2024, 8, 22, 0, 0), end_date=datetime.datetime(2024, 8, 30, 0, 0), location=Location(latitude=-20.0, longitude=np.float64(120.0)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=81, title='July/August 2024 Japan', start_date=datetime.datetime(2024, 7, 25, 0, 0), end_date=datetime.datetime(2024, 8, 5, 0, 0), location=Location(latitude=36.0, longitude=np.float64(138.0)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=82, title='June 2024 Saudi Arabia', start_date=datetime.datetime(2024, 6, 16, 0, 0), end_date=datetime.datetime(2024, 6, 18, 0, 0), location=Location(latitude=24.0, longitude=np.float64(45.0)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=83, title='August 2024 Europe', start_date=datetime.datetime(2024, 8, 10, 0, 0), end_date=datetime.datetime(2024, 8, 15, 0, 0), location=Location(latitude=48.3794, longitude=np.float64(10.8978)), bounding_box_degrees=10, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=84, title='July 2024 Ukraine', start_date=datetime.datetime(2024, 7, 12, 0, 0), end_date=datetime.datetime(2024, 7, 16, 0, 0), location=Location(latitude=50.4501, longitude=np.float64(30.5234)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=85, title='June 2024 Europe', start_date=datetime.datetime(2024, 6, 20, 0, 0), end_date=datetime.datetime(2024, 6, 30, 0, 0), location=Location(latitude=52.3676, longitude=np.float64(4.9041)), bounding_box_degrees=6, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=86, title='May 2024 Central Mexico', start_date=datetime.datetime(2024, 5, 23, 0, 0), end_date=datetime.datetime(2024, 5, 31, 0, 0), location=Location(latitude=19.4326, longitude=np.float64(260.8668)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=87, title='May 2024 Pakistan/India', start_date=datetime.datetime(2024, 5, 23, 0, 0), end_date=datetime.datetime(2024, 5, 31, 0, 0), location=Location(latitude=34.0, longitude=np.float64(76.0)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None), IndividualCase(case_id_number=88, title='August 2023 Chile', start_date=datetime.datetime(2023, 8, 1, 0, 0), end_date=datetime.datetime(2023, 8, 3, 0, 0), location=Location(latitude=-33.4489, longitude=np.float64(289.3307)), bounding_box_degrees=5, event_type='heat_wave', data_vars=None, cross_listed=None)])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_yaml = utils.load_events_yaml()\n",
    "heat_waves = HeatWave(case_metadata=case_yaml, \n",
    "                      metrics=[MaximumMAE, RegionalRMSE], \n",
    "                      observations=[ERA5(name='era5', variable='t2m', units='K')])\n",
    "\n",
    "heat_waves._build_case_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
