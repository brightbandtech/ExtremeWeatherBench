{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1504.09s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.1 environment at: /Users/taylor/code/ExtremeWeatherBench/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 42ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install virtualizarr[all_parsers, all_writers] sparse polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, List, Optional, Union, Callable\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dacite\n",
    "from scores.continuous import mae, rmse, mean_error\n",
    "import scores.categorical as cat\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from extremeweatherbench import regions, case, utils\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from obstore.store import from_url\n",
    "from virtualizarr.registry import ObjectStoreRegistry\n",
    "\n",
    "\n",
    "import refactor_scripts as rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "1. An easy? solution to dealing with variable mapping:\n",
    "    - Create a list of the names of each variable used in EWB that users can extend\n",
    "    - Each Observation should have a default mapping; if it's our observation default we will know the variable names coming in. Users will need to know the names of theirs as well.\n",
    "    - Forecasts will be able to access this mapping as well and can be provided in the ExtremeWeatherBench call\n",
    "2. ~~AppliedMetrics will define exactly what observations, observation variables, and forecast variables to use~~\n",
    "    - I think this is wrong now, it should be defined at the Event level.\n",
    "3. Defining the order of orchestration is still an open question. I guess this will come as I wire the components together... We're running each case as its own entity, thus:\n",
    "    - Each case will have multiple metrics that might or might not reuse Observations and Forecasts. Do metrics inside cases define the variables and DerivedVariables? Or should the EventType? Leaning towards EventType. DerivedVariables hold information on what core variables are needed.\n",
    "        1. Observation(s) should be built first which defines the dimensions for Forecasts. **DONE**\n",
    "        2. Observation(s) derived variables should be processed next. **DONE**\n",
    "        3. Forecasts should then be spatiotemporally subset to the Observation(s). **DONE**\n",
    "        4. Forecasts derived variables should then be processed. **DONE**\n",
    "        5. Might be worth then temporally subsetting the Observation(s) to the Forecasts\n",
    "        6. Finally, run applied metrics that use the Observation(s) and Forecasts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DerivedVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DerivedVariable(ABC):\n",
    "    \"\"\"A abstract base class defining the interface for ExtremeWeatherBench derived variables.\n",
    "    \n",
    "    A DerivedVariable is any variable that requires extra computation than what is \n",
    "    provided in analysis or forecast data. Some examples include the practically perfect hindcast, MLCAPE, IVT, or atmospheric river masks. \n",
    "    \n",
    "    Attributes:\n",
    "        name: The name that is used for applications of derived variables. Defaults to the class name.\n",
    "        input_variables: A list of variables that are used to build the variable.\n",
    "        build: A method that builds the variable from the input variables. Build is used\n",
    "        specifically to distinguish from the compute method, which eagerly processes the \n",
    "        data and loads into memory; build is used to lazily process the data and return a dataset that can be used to compute the variable.\n",
    "        compute: A method that computes the variable from the input variables using the build method, returning the final product.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        'A name for the derived variable. Defaults to the class name.'\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def input_variables(self) -> List[str]:\n",
    "        \"\"\"A list of variables that are used to compute the variable.\n",
    "        \n",
    "        Each derived variable is a product of one or more variables in an incoming dataset.\n",
    "        The input variables should be the names of the variables in the incoming dataset, not the final product.\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def build(self, case: case.IndividualCase, data: xr.Dataset, variable_mapping: dict[str, str]) -> xr.DataArray:\n",
    "        \"\"\"Build the variable from the input variables.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def compute(self, case: case.IndividualCase, data: xr.Dataset, variables: Optional[List[str]] = None) -> xr.DataArray:\n",
    "        \"\"\"Computes the variable from the input variables.\"\"\"\n",
    "        return self.build(case, data, variables).compute()\n",
    "\n",
    "# TODO: assign LSRs to a 0.25 degree grid\n",
    "class PracticallyPerfectHindcast(DerivedVariable):\n",
    "    \"\"\"A derived variable that computes the practically perfect hindcast.\"\"\"\n",
    "\n",
    "    name = \"practically_perfect_hindcast\"\n",
    "    input_variables = ['report_type']\n",
    "\n",
    "    def build(self, case: case.IndividualCase, data: xr.Dataset, variables: Optional[List[str]] = None) -> xr.DataArray:\n",
    "        \"\"\"Process the practically perfect hindcast.\"\"\"\n",
    "        pph = rs.practically_perfect_hindcast(data[self.input_variables], output_bounds = case.location, report_type = ['tor', 'hail'])\n",
    "        return pph['practically_perfect']\n",
    "    \n",
    "class CravenSignificantSevereParameter(DerivedVariable):\n",
    "    \"\"\"A derived variable that computes the Craven significant severe parameter.\"\"\"\n",
    "\n",
    "    name = \"craven_significant_severe_parameter\"\n",
    "    input_variables = [\n",
    "        '2m_temperature', \n",
    "        '2m_dewpoint_temperature',\n",
    "        '2m_relative_humidity',\n",
    "        '10m_u_component_of_wind',\n",
    "        '10m_v_component_of_wind',\n",
    "        'surface_pressure',\n",
    "        'geopotential'\n",
    "    ]\n",
    "\n",
    "    def build(self, case: case.IndividualCase, data: xr.Dataset, variables: Optional[List[str]] = None) -> xr.DataArray:\n",
    "        \"\"\"Build the Craven significant severe parameter.\"\"\"\n",
    "        # cbss_ds = calc.craven_brooks_sig_svr(data[variables],variable_mapping={'pressure':'level', 'dewpoint':'dewpoint_temperature','temperature':'air_temperature'})\n",
    "        test_da = data[variables[0]]*2\n",
    "        return test_da\n",
    "    \n",
    "def maybe_derive_variables(\n",
    "        ds: xr.Dataset, case: case.IndividualCase, variables: list[str | DerivedVariable]\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Derive variables from the data if any exist in a list of variables.\n",
    "\n",
    "    Derived variables must maintain the same spatial dimensions as the original dataset.\n",
    "\n",
    "    Args:\n",
    "        ds: The dataset, ideally already subset in case of in memory operations in the derived variables.\n",
    "        case: The case to derive the variables for.\n",
    "        variables: The potential variables to derive as a list of strings or DerivedVariable objects.\n",
    "\n",
    "    Returns:\n",
    "        A dataset with derived variables, if any exist, else the original dataset.\n",
    "    \"\"\"\n",
    "    derived_variables = {}\n",
    "\n",
    "    non_derived_variables = [v for v in variables if v in ds.data_vars]\n",
    "    derived_variables = [v for v in variables if not isinstance(v, str)]\n",
    "    if derived_variables:\n",
    "        for v in derived_variables:\n",
    "            derived_variable = v()\n",
    "            derived_data = derived_variable.build(case=case, data=ds, variables=non_derived_variables)\n",
    "            ds[derived_variable.name] = derived_data\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics:\n",
    "\n",
    "It seems logical to split up simple metrics, e.g. MAE, and more complicated split-apply-combine or other methods that requires multiple steps to prepare for said simple metric. These more complicated metrics are \"AppliedMetrics\", and can optionally include the simple metrics. Some metrics part of EWB don't have a simple metric downstream, such as categorical thresholds and contingency table metrics. This is a bit of a WIP so will update as the orchestration becomes more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMetric(ABC):\n",
    "    \"\"\"A BaseMetric class is an abstract class that defines the foundational interface for all metrics.\n",
    "    \n",
    "    Metrics are general operations applied between a forecast and analysis \n",
    "    xarray dataset. EWB metrics prioritize the use of any arbitrary sets of forecasts\n",
    "    and analyses, so long as the spatiotemporal dimensions are the same.\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        pass\n",
    "\n",
    "class AppliedMetric(ABC):\n",
    "    \"\"\"An applied metric is a derivative of a BaseMetric.\n",
    "\n",
    "    It is a wrapper around one or more BaseMetrics that is intended for more complex rollups or aggregations.\n",
    "    Typically, these metrics are used for one event type and are very specific. Temporal onset mean error,\n",
    "    case duration mean error, and maximum temperature mean absolute error, are all examples of applied metrics.\n",
    "\n",
    "    Attributes:\n",
    "        base_metrics: A list of BaseMetrics to compute.\n",
    "        compute_metric: A required method to compute the metric.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.__class__.__name__\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def base_metrics(self) -> list[BaseMetric]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset, forecast_variables: list[str], observation_variables: list[str],**kwargs):\n",
    "        pass\n",
    "\n",
    "class MAE(BaseMetric):\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return mae(forecast, observation, **kwargs)\n",
    "\n",
    "class ME(BaseMetric):\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return mean_error(forecast, observation, **kwargs)\n",
    "\n",
    "class RMSE(BaseMetric):\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return rmse(forecast, observation, **kwargs)\n",
    "\n",
    "class BinaryContingencyTable(BaseMetric):\n",
    "    def compute(self, forecast: xr.Dataset, observation: xr.Dataset, **kwargs):\n",
    "        return cat.BinaryContingencyManager(forecast, observation, **kwargs)\n",
    "\n",
    "class MaximumMAE(AppliedMetric):\n",
    "\n",
    "    base_metric = [MAE]\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset, forecast_variables: list[str], observation_variables: list[str]):\n",
    "        maximum_timestep = observation.mean([\"latitude\", \"longitude\"]).idxmax(\"valid_time\").values\n",
    "        maximum_value = observation.mean([\"latitude\", \"longitude\"]).sel(valid_time=maximum_timestep).values\n",
    "        forecast_spatial_mean = forecast.mean([\"latitude\", \"longitude\"])\n",
    "        filtered_max_forecast = forecast_spatial_mean.mean(['latitude','longitude']).where(\n",
    "            (forecast_spatial_mean.valid_time >= maximum_timestep - np.timedelta64(48, 'h')) & \n",
    "            (forecast_spatial_mean.valid_time <= maximum_timestep + np.timedelta64(48, 'h')),\n",
    "            drop=True\n",
    "        ).max('valid_time')\n",
    "        return self.base_metric().compute(filtered_max_forecast, maximum_value)\n",
    "    \n",
    "\n",
    "class MaxMinMAE(AppliedMetric):\n",
    "    base_metric = MAE\n",
    "\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for finding both max and min values\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class OnsetME(AppliedMetric):\n",
    "    base_metric = ME\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for onset mean error\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class DurationME(AppliedMetric):\n",
    "    base_metric = MAE\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for duration mean error\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class CSI(AppliedMetric):\n",
    "    base_metric = BinaryContingencyTable\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for Critical Success Index\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class LeadTimeDetection(AppliedMetric):\n",
    "    base_metric = MAE\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for lead time detection\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class RegionalHitsMisses(AppliedMetric):\n",
    "    base_metric = BinaryContingencyTable\n",
    "    def __init__(self, variables: list[str | DerivedVariable]):\n",
    "        super().__init__(variables)\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for regional hits and misses\n",
    "        return self.metric().compute(forecast, observation)\n",
    "\n",
    "class HitsMisses(AppliedMetric):\n",
    "    base_metric = BinaryContingencyTable\n",
    "    def __init__(self, variables: list[str | DerivedVariable], threshold: float = 0.5):\n",
    "        super().__init__(variables)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute_metric(self, forecast: xr.Dataset, observation: xr.Dataset):\n",
    "        # Dummy implementation for hits and misses\n",
    "        return self.metric().compute(forecast, observation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "commenting out for now with the impression the module is operating as intended with the same code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: Storage/access options for gridded observation datasets.\n",
    "ARCO_ERA5_FULL_URI = (\n",
    "    \"gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3\"\n",
    ")\n",
    "\n",
    "#: Storage/access options for default point observation dataset.\n",
    "DEFAULT_GHCN_URI = \"gs://extremeweatherbench/datasets/ghcnh.parq\"\n",
    "\n",
    "#: Storage/access options for local storm report (LSR) tabular data.\n",
    "LSR_URI = \"gs://extremeweatherbench/datasets/lsr_01012020_04302025.parq\"\n",
    "\n",
    "IBTRACS_URI = \"https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r01/access/csv/ibtracs.ALL.list.v04r01.csv\"  # noqa: E501\n",
    "\n",
    "# type hint for the data input to the observation classes\n",
    "IncomingDataInput = Union[\n",
    "    xr.Dataset, xr.DataArray, pl.LazyFrame, pd.DataFrame, np.ndarray\n",
    "]\n",
    "\n",
    "\n",
    "class Observation(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all observation types.\n",
    "\n",
    "    An Observation is data that acts as the \"truth\" for a case. It can be a gridded dataset,\n",
    "    a point observation dataset, or any other reference dataset. Observations in EWB\n",
    "    are not required to be the same variable as the forecast dataset, but they must be in the\n",
    "    same coordinate system for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    source: str\n",
    "\n",
    "    @abstractmethod\n",
    "    def _open_data_from_source(\n",
    "        self, storage_options: Optional[dict] = None, **kwargs\n",
    "    ) -> IncomingDataInput:\n",
    "        \"\"\"\n",
    "        Open the observation data from the source, opting to avoid loading the entire dataset into memory if possible.\n",
    "\n",
    "        Args:\n",
    "            source: The source of the observation data, which can be a local path or a remote URL.\n",
    "            storage_options: Optional storage options for the source if the source is a remote URL.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with a type determined by the user.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        data: IncomingDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        observation_variables: Optional[list[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "        \"\"\"\n",
    "        Subset the observation data to the case information provided in IndividualCase.\n",
    "\n",
    "        Time information, spatial bounds, and variables are captured in the case metadata\n",
    "        where this method is used to subset.\n",
    "\n",
    "        Args:\n",
    "            data: The observation data to subset, which should be a xarray dataset, xarray dataarray, polars lazyframe,\n",
    "            pandas dataframe, or numpy array.\n",
    "            observation_variables: The variables to include in the observation. Some observations may not have variables, or\n",
    "            only have a singular variable; thus, this is optional.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with the variables subset to the case metadata.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _maybe_convert_to_dataset(self, data: IncomingDataInput, **kwargs) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Convert the observation data to an xarray dataset if it is not already.\n",
    "\n",
    "        If this method is used prior to _subset_data_to_case, OOM errors are possible\n",
    "        prior to subsetting.\n",
    "\n",
    "        Args:\n",
    "            data: The observation data already run through _subset_data_to_case.\n",
    "\n",
    "        Returns:\n",
    "            The observation data as an xarray dataset.\n",
    "        \"\"\"\n",
    "\n",
    "    def run_pipeline(\n",
    "        self,\n",
    "        case: case.IndividualCase,\n",
    "        storage_options: Optional[dict] = None,\n",
    "        observation_variables: Optional[list[str | DerivedVariable]] = None,\n",
    "        observation_variable_mapping: dict = {},\n",
    "        **kwargs,\n",
    "    ) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Shared method for running the observation pipeline.\n",
    "\n",
    "        Args:\n",
    "            source: The source of the observation data, which can be a local path or a remote URL.\n",
    "            storage_options: Optional storage options for the source if the source is a remote URL.\n",
    "            variables: The variables to include in the observation. Some observations may not have variables, or\n",
    "            only have a singular variable; thus, this is optional.\n",
    "            variable_mapping: A dictionary of variable names to map to the observation data.\n",
    "            **kwargs: Additional keyword arguments to pass in as needed.\n",
    "\n",
    "        Returns:\n",
    "            The observation data with a type determined by the user.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # Open data and process through pipeline steps\n",
    "        data = (\n",
    "            self._open_data_from_source(\n",
    "                storage_options=storage_options,\n",
    "                **kwargs,\n",
    "            )\n",
    "            .pipe(\n",
    "                rs.maybe_map_variable_names,\n",
    "                variable_mapping=observation_variable_mapping,\n",
    "                **kwargs,\n",
    "            )\n",
    "            .pipe(\n",
    "                self._subset_data_to_case,\n",
    "                case=case,\n",
    "                observation_variables=observation_variables,\n",
    "                **kwargs,\n",
    "            )\n",
    "            .pipe(self._maybe_convert_to_dataset, **kwargs)\n",
    "            .pipe(\n",
    "                maybe_derive_variables,  \n",
    "                case=case, \n",
    "                variables=observation_variables\n",
    "                )\n",
    "        )\n",
    "        return data\n",
    "\n",
    "\n",
    "class ERA5(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for ERA5 gridded data.\n",
    "\n",
    "    The easiest approach to using this class\n",
    "    is to use the ARCO ERA5 dataset provided by Google for a source. Otherwise, either a\n",
    "    different zarr source or modifying the _open_data_from_source method to open the data\n",
    "    using another method is required.\n",
    "    \"\"\"\n",
    "\n",
    "    source: str = ARCO_ERA5_FULL_URI\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, \n",
    "        storage_options: Optional[dict] = None, \n",
    "        chunks: dict = {'time': 48, 'latitude': 721, 'longitude': 1440},\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "        data = xr.open_zarr(\n",
    "            self.source,\n",
    "            storage_options=storage_options,\n",
    "            chunks=chunks,\n",
    "        )\n",
    "        return data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        data: IncomingDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        observation_variables: Optional[list[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "\n",
    "        if not isinstance(data, (xr.Dataset, xr.DataArray)):\n",
    "            raise ValueError(f\"Expected xarray Dataset or DataArray, got {type(data)}\")\n",
    "\n",
    "        # subset time first to avoid OOM masking issues\n",
    "        subset_time_data = data.sel(time=slice(case.start_date, case.end_date))\n",
    "\n",
    "        # check that the variables are in the observation data\n",
    "        if observation_variables is not None and any(\n",
    "            var not in subset_time_data.data_vars for var in observation_variables\n",
    "        ):\n",
    "            raise ValueError(f\"Variables {observation_variables} not found in observation data\")\n",
    "        # subset the variables\n",
    "        elif observation_variables is not None:\n",
    "            subset_time_variable_data = subset_time_data[observation_variables]\n",
    "        else:\n",
    "            raise ValueError(\"Variables not defined for ERA5. Please list at least one variable to select.\")\n",
    "        # # calling chunk here to avoid loading subset_data into memory\n",
    "        chunks = kwargs.get('chunks', {'time': 48, 'latitude': 721, 'longitude': 1440})\n",
    "        subset_time_variable_data = subset_time_variable_data.chunk(chunks) \n",
    "        # mask the data to the case location\n",
    "        fully_subset_data = case.location.mask(subset_time_variable_data, drop=True)\n",
    "\n",
    "        return fully_subset_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: IncomingDataInput, **kwargs):\n",
    "        if isinstance(data, xr.DataArray):\n",
    "            data = data.to_dataset()\n",
    "        return data\n",
    "\n",
    "\n",
    "class GHCN(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for GHCN tabular data.\n",
    "\n",
    "    Data is processed using polars to maintain the lazy loading\n",
    "    paradigm in _open_data_from_source and to separate the subsetting\n",
    "    into _subset_data_to_case.\n",
    "    \"\"\"\n",
    "\n",
    "    source: str = DEFAULT_GHCN_URI\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, storage_options: Optional[dict] = None, **kwargs\n",
    "    ) -> IncomingDataInput:\n",
    "        observation_data: pl.LazyFrame = pl.scan_parquet(\n",
    "            self.source, storage_options=storage_options\n",
    "        )\n",
    "\n",
    "        return observation_data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        observation_data: IncomingDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        observation_variables: Optional[list[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "        # Create filter expressions for LazyFrame\n",
    "        time_min = case.start_date - pd.Timedelta(days=2)\n",
    "        time_max = case.end_date + pd.Timedelta(days=2)\n",
    "\n",
    "        if not isinstance(observation_data, pl.LazyFrame):\n",
    "            raise ValueError(f\"Expected polars LazyFrame, got {type(observation_data)}\")\n",
    "\n",
    "        # Apply filters using proper polars expressions\n",
    "        subset_observation_data = observation_data.filter(\n",
    "            (pl.col(\"time\") >= time_min)\n",
    "            & (pl.col(\"time\") <= time_max)\n",
    "            & (pl.col(\"latitude\") >= case.location.latitude_min)\n",
    "            & (pl.col(\"latitude\") <= case.location.latitude_max)\n",
    "            & (pl.col(\"longitude\") >= case.location.longitude_min)\n",
    "            & (pl.col(\"longitude\") <= case.location.longitude_max)\n",
    "        )\n",
    "\n",
    "        # Add time, latitude, and longitude to the variables, polars doesn't do indexes\n",
    "        if observation_variables is None:\n",
    "            all_variables = [\"time\", \"latitude\", \"longitude\"]\n",
    "        else:\n",
    "            all_variables = observation_variables + [\"time\", \"latitude\", \"longitude\"]\n",
    "\n",
    "        # check that the variables are in the observation data\n",
    "        schema_fields = [field for field in subset_observation_data.collect_schema()]\n",
    "        if observation_variables is not None and any(\n",
    "            var not in schema_fields for var in all_variables\n",
    "        ):\n",
    "            raise ValueError(f\"Variables {all_variables} not found in observation data\")\n",
    "\n",
    "        # subset the variables\n",
    "        if observation_variables is not None:\n",
    "            subset_observation_data = subset_observation_data.select(all_variables)\n",
    "\n",
    "        return subset_observation_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: IncomingDataInput, **kwargs):\n",
    "        if isinstance(data, pl.LazyFrame):\n",
    "            data = data.collect().to_pandas()\n",
    "            data = data.set_index([\"time\", \"latitude\", \"longitude\"])\n",
    "            # GHCN data can have duplicate values right now, dropping here if it occurs\n",
    "            try:\n",
    "                data = data.to_xarray()\n",
    "            except ValueError as e:\n",
    "                if \"non-unique\" in str(e):\n",
    "                    pass\n",
    "                data = data.drop_duplicates().to_xarray()\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Data is not a polars LazyFrame: {type(data)}\")\n",
    "\n",
    "class LSR(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for local storm report (LSR) tabular data.\n",
    "\n",
    "    run_pipeline() returns a dataset with LSRs and practically perfect hindcast gridded\n",
    "    probability data. IndividualCase date ranges for LSRs should ideally be\n",
    "    12 UTC to the next day at 12 UTC to match SPC methods.\n",
    "    \"\"\"\n",
    "\n",
    "    source: str = LSR_URI\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, storage_options: Optional[dict] = None, **kwargs\n",
    "    ) -> IncomingDataInput:\n",
    "        \n",
    "        # force LSR to use anon token to prevent google reauth issues for users\n",
    "        observation_data = pd.read_parquet(self.source, storage_options={'token': 'anon'})\n",
    "\n",
    "        return observation_data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        observation_data: IncomingDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        variables: Optional[list[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "        if not isinstance(observation_data, pd.DataFrame):\n",
    "            raise ValueError(f\"Expected pandas DataFrame, got {type(observation_data)}\")\n",
    "\n",
    "        # latitude, longitude are strings by default, convert to float\n",
    "        observation_data[\"lat\"] = observation_data[\"lat\"].astype(float)\n",
    "        observation_data[\"lon\"] = observation_data[\"lon\"].astype(float)\n",
    "        observation_data[\"time\"] = pd.to_datetime(observation_data[\"time\"])\n",
    "\n",
    "        filters = (\n",
    "            (observation_data[\"time\"] >= case.start_date)\n",
    "            & (observation_data[\"time\"] <= case.end_date)\n",
    "            & (observation_data[\"lat\"] >= case.location.latitude_min)\n",
    "            & (observation_data[\"lat\"] <= case.location.latitude_max)\n",
    "            & (observation_data[\"lon\"] >= rs.convert_longitude_to_180(case.location.longitude_min))\n",
    "            & (observation_data[\"lon\"] <= rs.convert_longitude_to_180(case.location.longitude_max))\n",
    "        )\n",
    "\n",
    "        subset_observation_data = observation_data.loc[filters]\n",
    "\n",
    "        subset_observation_data = subset_observation_data.rename(\n",
    "            columns={\"lat\": \"latitude\", \"lon\": \"longitude\", \"time\": \"valid_time\"}\n",
    "        )\n",
    "\n",
    "        return subset_observation_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: IncomingDataInput, **kwargs):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data = data.set_index([\"valid_time\", \"latitude\", \"longitude\"])\n",
    "            data = xr.Dataset.from_dataframe(data[~data.index.duplicated(keep='first')],sparse=True)\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Data is not a pandas DataFrame: {type(data)}\")\n",
    "\n",
    "class IBTrACS(Observation):\n",
    "    \"\"\"\n",
    "    Observation class for IBTrACS data.\n",
    "    \"\"\"\n",
    "\n",
    "    source: str = IBTRACS_URI\n",
    "\n",
    "    def _open_data_from_source(\n",
    "        self, storage_options: Optional[dict] = None, **kwargs\n",
    "    ) -> IncomingDataInput:\n",
    "        # not using storage_options in this case due to NetCDF4Backend not supporting them\n",
    "        observation_data: pl.LazyFrame = pl.scan_csv(\n",
    "            self.source, storage_options=storage_options\n",
    "        )\n",
    "        return observation_data\n",
    "\n",
    "    def _subset_data_to_case(\n",
    "        self,\n",
    "        observation_data: IncomingDataInput,\n",
    "        case: case.IndividualCase,\n",
    "        variables: Optional[list[str]] = None,\n",
    "        **kwargs,\n",
    "    ) -> IncomingDataInput:\n",
    "        # Create filter expressions for LazyFrame\n",
    "        year = case.start_date.year\n",
    "\n",
    "        if not isinstance(observation_data, pl.LazyFrame):\n",
    "            raise ValueError(f\"Expected polars LazyFrame, got {type(observation_data)}\")\n",
    "\n",
    "        # Apply filters using proper polars expressions\n",
    "        subset_observation_data = observation_data.filter(\n",
    "            (pl.col(\"NAME\") == case.title.upper())\n",
    "        )\n",
    "\n",
    "        all_variables = [\n",
    "            \"SEASON\",\n",
    "            \"NUMBER\",\n",
    "            \"NAME\",\n",
    "            \"ISO_TIME\",\n",
    "            \"LAT\",\n",
    "            \"LON\",\n",
    "            \"WMO_WIND\",\n",
    "            \"USA_WIND\",\n",
    "            \"WMO_PRES\",\n",
    "            \"USA_PRES\",\n",
    "        ]\n",
    "        # Get the season (year) from the case start date, cast as string as polars is interpreting the schema as strings\n",
    "        season = str(year)\n",
    "\n",
    "        # First filter by name to get the storm data\n",
    "        subset_observation_data = observation_data.filter(\n",
    "            (pl.col(\"NAME\") == case.title.upper())\n",
    "        )\n",
    "\n",
    "        # Create a subquery to find all storm numbers in the same season\n",
    "        matching_numbers = (\n",
    "            subset_observation_data.filter(pl.col(\"SEASON\") == season)\n",
    "            .select(\"NUMBER\")\n",
    "            .unique()\n",
    "        )\n",
    "\n",
    "        # Apply the filter to get all data for storms with the same number in the same season\n",
    "        # This maintains the lazy evaluation\n",
    "        subset_observation_data = observation_data.join(\n",
    "            matching_numbers, on=\"NUMBER\", how=\"inner\"\n",
    "        ).filter((pl.col(\"NAME\") == case.title.upper()) & (pl.col(\"SEASON\") == season))\n",
    "\n",
    "        # check that the variables are in the observation data\n",
    "        schema_fields = [field for field in subset_observation_data.collect_schema()]\n",
    "        if variables is not None and any(\n",
    "            var not in schema_fields for var in all_variables\n",
    "        ):\n",
    "            raise ValueError(f\"Variables {all_variables} not found in observation data\")\n",
    "\n",
    "        # subset the variables\n",
    "        if variables is not None:\n",
    "            subset_observation_data = subset_observation_data.select(all_variables)\n",
    "\n",
    "        return subset_observation_data\n",
    "\n",
    "    def _maybe_convert_to_dataset(self, data: IncomingDataInput, **kwargs):\n",
    "        if isinstance(data, pl.LazyFrame):\n",
    "            data = data.collect().to_pandas()\n",
    "            data = data.set_index([\"ISO_TIME\"])\n",
    "            try:\n",
    "                data = data.to_xarray()\n",
    "            except ValueError as e:\n",
    "                if \"non-unique\" in str(e):\n",
    "                    pass\n",
    "                data = data.drop_duplicates().to_xarray()\n",
    "            return data\n",
    "        else:\n",
    "            raise ValueError(f\"Data is not a polars LazyFrame: {type(data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO implement this in case.py\n",
    "@dataclasses.dataclass\n",
    "class BaseCaseMetadataCollection:\n",
    "    cases: List[case.IndividualCase]\n",
    "\n",
    "    def subset_cases_by_event_type(self, event_type: str) -> List[case.IndividualCase]:\n",
    "        \"\"\"Subset the cases in the collection by event type.\"\"\"\n",
    "        return [c for c in self.cases if c.event_type == event_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class CaseOperator:\n",
    "    \"\"\"A class which stores the graph to process an individual case.\"\"\"\n",
    "    \n",
    "    case: case.IndividualCase\n",
    "    metrics: list[BaseMetric]\n",
    "    observations: list[Observation]\n",
    "    observation_variables: list[str | DerivedVariable]\n",
    "    forecast_variables: list[str | DerivedVariable]\n",
    "\n",
    "    \n",
    "    def evaluate_case(self, forecast: xr.Dataset):\n",
    "        \"\"\"Process a case.\"\"\"\n",
    "        self.process_metrics(forecast)\n",
    "        \n",
    "    def process_metrics(self, forecast: xr.Dataset):\n",
    "        \"\"\"Process the metrics.\"\"\"\n",
    "        for metric in self.metrics:\n",
    "            metric.process_metric(forecast, self.observations)\n",
    "\n",
    "    def build_observations(self, **kwargs) -> list[xr.Dataset]:\n",
    "        \"\"\"Build observation xarray Datasets from the observation sources.\"\"\"\n",
    "        observation_storage_options = kwargs.get('observation_storage_options', {'remote_protocol': 's3', 'remote_options': {'anon': True}})\n",
    "        observation_variable_mapping = kwargs.get('observation_variable_mapping', {'anon': True})\n",
    "        observation_datasets = []\n",
    "        for observation in self.observations:\n",
    "            #TODO: need to pipe in storage options here\n",
    "            obs_dataset = observation().run_pipeline(case=self.case, storage_options=observation_storage_options, observation_variables=self.observation_variables, observation_variable_mapping=observation_variable_mapping)\n",
    "            observation_datasets.append(obs_dataset)\n",
    "\n",
    "        return observation_datasets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventType(ABC):\n",
    "    \"\"\"A base class defining the interface for ExtremeWeatherBench event types.\n",
    "\n",
    "    An Event in ExtremeWeatherBench defines a specific weather event type, such as a heat wave,\n",
    "    severe convective weather, or atmospheric rivers. These events encapsulate a set of cases and\n",
    "    derived behavior for evaluating those cases. These cases will share common metrics, observations,\n",
    "    and variables while each having unique dates and locations.\n",
    "\n",
    "    Attributes:\n",
    "        event_type: The type of event.\n",
    "        forecast_variables: A list of variables that are used to forecast the event.\n",
    "        observation_variables: A list of variables that are used to observe the event.\n",
    "        case_metadata: A dictionary or yaml file with guiding metadata.\n",
    "        metrics: A list of Metrics that are used to evaluate the cases.\n",
    "        observations: A list of Observations that are used as targets for the metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        case_metadata: dict[str, Any],\n",
    "    ):\n",
    "        self.case_metadata = case_metadata\n",
    "        self._maybe_expand_not_derived_variables()\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def event_type(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def forecast_variables(self) -> List[str | DerivedVariable]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def observation_variables(self) -> List[str | DerivedVariable]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def metrics(self) -> List[AppliedMetric]:\n",
    "        pass\n",
    "\n",
    "    @property   \n",
    "    @abstractmethod\n",
    "    def observations(self) -> List[Observation]:\n",
    "        pass\n",
    "\n",
    "    def _maybe_expand_not_derived_variables(self) -> List[str | DerivedVariable]:\n",
    "        \"\"\"Expand the variables to include the input variables of any derived variables.\"\"\"\n",
    "        for v in self.forecast_variables:\n",
    "            if hasattr(v, 'input_variables'):\n",
    "                self.forecast_variables = self.forecast_variables + v.input_variables\n",
    "        \n",
    "        for v in self.observation_variables:\n",
    "            if hasattr(v, 'input_variables'):\n",
    "                self.observation_variables = self.observation_variables + v.input_variables\n",
    "\n",
    "    def _build_base_case_metadata_collection(self) -> BaseCaseMetadataCollection:\n",
    "        \"\"\"Build a list of IndividualCases from the case_metadata.\"\"\"\n",
    "        cases = dacite.from_dict(\n",
    "            data_class=BaseCaseMetadataCollection, \n",
    "            data=self.case_metadata, \n",
    "            config=dacite.Config(\n",
    "                    type_hooks={regions.Region: regions.map_to_create_region},\n",
    "                ),\n",
    "        )\n",
    "        cases = BaseCaseMetadataCollection(cases=[c for c in cases.cases if c.event_type == self.event_type])\n",
    "        return cases\n",
    "    \n",
    "    def build_case_operators(self, observation_storage_options: dict[str, Any], observation_variable_mapping: dict[str, str]) -> list[CaseOperator]:\n",
    "        \"\"\"Build a CaseOperator from the event type.\"\"\"\n",
    "        case_metadata_collection = self._build_base_case_metadata_collection()\n",
    "        case_operators = [\n",
    "            CaseOperator(\n",
    "                case = case,\n",
    "                metrics = self.metrics,\n",
    "                observations = self.observations,\n",
    "                observation_variables=self.observation_variables,\n",
    "                forecast_variables=self.forecast_variables\n",
    "                ) \n",
    "                for case in case_metadata_collection.cases\n",
    "                ]\n",
    "        return case_operators\n",
    "\n",
    "class HeatWave(EventType):\n",
    "    event_type = 'heat_wave'\n",
    "    forecast_variables = ['surface_air_temperature']\n",
    "    observation_variables = ['surface_air_temperature']\n",
    "    metrics = [MaximumMAE,\n",
    "               MaxMinMAE, \n",
    "               RMSE,\n",
    "               OnsetME,\n",
    "               DurationME]\n",
    "    observations = [ERA5]\n",
    "\n",
    "class SevereConvection(EventType):\n",
    "    event_type = 'severe_convection'\n",
    "    forecast_variables = [\n",
    "        CravenSignificantSevereParameter,\n",
    "    ]\n",
    "    observation_variables = [\n",
    "        PracticallyPerfectHindcast,\n",
    "    ]\n",
    "    metrics = [CSI, \n",
    "               LeadTimeDetection, \n",
    "               RegionalHitsMisses, \n",
    "               HitsMisses]\n",
    "    observations = [LSR]\n",
    "\n",
    "\n",
    "class AtmosphericRiver(EventType):\n",
    "    event_type = 'atmospheric_river'\n",
    "    forecast_variables = []\n",
    "    observation_variables = []\n",
    "    metrics = [CSI, \n",
    "               LeadTimeDetection]\n",
    "    observations = [ERA5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_preprocess_forecast_dataset(\n",
    "    forecast_dir: str,\n",
    "    forecast_variables: list[str | DerivedVariable],\n",
    "    forecast_variable_mapping: dict[str, list[str | DerivedVariable]],\n",
    "    forecast_preprocess: Callable = utils._default_preprocess,\n",
    "    forecast_storage_options: dict = {\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}},\n",
    "    forecast_chunks: dict = {\"time\": 48, \"latitude\": 721, \"longitude\": 1440},\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Open the forecast dataset specified for evaluation.\n",
    "\n",
    "    If a URI is provided (e.g. s3://bucket/path/to/forecast), the filesystem\n",
    "    will be inferred from the provided source (in this case, s3). Otherwise,\n",
    "    the filesystem will assumed to be local.\n",
    "\n",
    "    Preprocessing examples:\n",
    "        A typical preprocess function handles metadata changes:\n",
    "\n",
    "        def _preprocess_cira_forecast_dataset(\n",
    "            ds: xr.Dataset\n",
    "        ) -> xr.Dataset:\n",
    "            ds = ds.rename({\"time\": \"lead_time\"})\n",
    "            return ds\n",
    "\n",
    "        The preprocess function is applied before variable renaming occurs, so it should\n",
    "        reference the original variable names in the forecast dataset, not the standardized\n",
    "        names defined in the ForecastSchemaConfig.\n",
    "\n",
    "    Args:\n",
    "        eval_config: The evaluation configuration.\n",
    "        forecast_schema_config: The forecast schema configuration.\n",
    "        preprocess: A function that preprocesses the forecast dataset.\n",
    "\n",
    "    Returns:\n",
    "        The opened forecast dataset.\n",
    "    \"\"\"\n",
    "    if \"zarr\" in forecast_dir:\n",
    "        forecast_ds = xr.open_zarr(forecast_dir, chunks=forecast_chunks)\n",
    "    elif (\n",
    "        \"parq\" in forecast_dir\n",
    "        or \"json\" in forecast_dir\n",
    "        or \"parquet\" in forecast_dir\n",
    "    ):\n",
    "        forecast_ds = open_kerchunk_reference(forecast_dir, storage_options=forecast_storage_options, chunks=forecast_chunks)\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"Unknown file type found in forecast path, only json, parquet, and zarr are supported.\"\n",
    "        )\n",
    "    forecast_ds = forecast_preprocess(forecast_ds)\n",
    "    forecast_ds = _maybe_rename_and_subset_forecast_dataset(\n",
    "        forecast_ds, forecast_variable_mapping\n",
    "    )\n",
    "    forecast_ds = _maybe_convert_dataset_lead_time_to_int(forecast_ds)\n",
    "\n",
    "    return forecast_ds\n",
    "\n",
    "\n",
    "def open_kerchunk_reference(\n",
    "    forecast_dir: str,\n",
    "    storage_options: dict = {\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}},\n",
    "    chunks: dict = {\"time\": 48, \"latitude\": 721, \"longitude\": 1440},\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Open a dataset from a kerchunked reference file in parquet or json format.\n",
    "    This has been built primarily for the CIRA MLWP S3 bucket's data (https://registry.opendata.aws/aiwp/),\n",
    "    but can work with other data in the future. Currently only supports CIRA data unless\n",
    "    schema is identical to the CIRA schema.\n",
    "\n",
    "    Args:\n",
    "        file: The path to the kerchunked reference file.\n",
    "        remote_protocol: The remote protocol to use.\n",
    "\n",
    "    Returns:\n",
    "        The opened dataset.\n",
    "    \"\"\"\n",
    "    if \"parq\" in forecast_dir or \"parquet\" in forecast_dir:\n",
    "        bucket = \"/\".join(forecast_dir.split(\"/\")[:3])\n",
    "        store = from_url(bucket, skip_signature=True)\n",
    "        \n",
    "        registry = ObjectStoreRegistry({bucket: store})\n",
    "        kerchunk_ds = xr.open_dataset(\n",
    "            forecast_dir,\n",
    "            engine=\"kerchunk\",\n",
    "            storage_options=storage_options\n",
    "        )\n",
    "        kerchunk_ds = kerchunk_ds.compute()\n",
    "    elif \"json\" in forecast_dir:\n",
    "        storage_options['fo'] = forecast_dir\n",
    "        kerchunk_ds = xr.open_dataset(\n",
    "            \"reference://\",\n",
    "            engine=\"zarr\",\n",
    "            backend_kwargs={\n",
    "                \"storage_options\": storage_options,\n",
    "                \"consolidated\": False,\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        raise TypeError(\n",
    "            \"Unknown kerchunk file type found in forecast path, only json and parquet are supported.\"\n",
    "        )\n",
    "    return kerchunk_ds\n",
    "\n",
    "\n",
    "def _maybe_rename_and_subset_forecast_dataset(\n",
    "    forecast_ds: xr.Dataset, variable_mapping: dict[str, list[str | DerivedVariable]]\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Rename the forecast dataset to the correct names expected by the evaluation routines.\n",
    "\n",
    "    Args:\n",
    "        forecast_ds: The forecast dataset to rename.\n",
    "        forecast_schema_config: The forecast schema configuration.\n",
    "\n",
    "    Returns:\n",
    "        The renamed forecast dataset.\n",
    "    \"\"\"\n",
    "    # Mapping here is used to rename the incoming data variables to the correct\n",
    "    # names expected by the evaluation routines.\n",
    "    mapping = {\n",
    "        variable: variable\n",
    "        for variable in variable_mapping.keys()\n",
    "    }\n",
    "    # Filter the mapping to only include variables that are in the forecast dataset, else\n",
    "    # an error will be raised.\n",
    "    mapping = {k: v for k, v in variable_mapping.items() if k in forecast_ds.data_vars}\n",
    "    variables = mapping.keys()\n",
    "    forecast_ds = forecast_ds[variables]\n",
    "    forecast_ds = forecast_ds.rename(mapping)\n",
    "\n",
    "    return forecast_ds\n",
    "\n",
    "\n",
    "def _maybe_convert_dataset_lead_time_to_int(\n",
    "    dataset: xr.Dataset\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Convert types of variables in an xarray Dataset based on the schema,\n",
    "    ensuring that, for example, the variable representing lead_time is of type int.\n",
    "\n",
    "    Args:\n",
    "        dataset: The input xarray Dataset that uses the schema's variable names.\n",
    "\n",
    "    Returns:\n",
    "        An xarray Dataset with adjusted types.\n",
    "    \"\"\"\n",
    "\n",
    "    lead_time = dataset[\"lead_time\"] if \"lead_time\" in dataset.data_vars else dataset[\"time\"]\n",
    "    if lead_time.dtype == np.dtype(\"timedelta64[ns]\"):\n",
    "        # Convert timedelta64[ns] to hours and cast to int\n",
    "        dataset[\"lead_time\"] = (lead_time / np.timedelta64(1, \"h\")).astype(int)\n",
    "    elif lead_time.dtype == np.dtype(\"int64\"):\n",
    "        # Already an int, do nothing\n",
    "        pass\n",
    "    else:\n",
    "        temporal_resolution_hours = np.squeeze(np.unique(np.diff(dataset['time'].values))/np.timedelta64(1, 'h'))\n",
    "        dataset[\"time\"] = np.arange(0, dataset['time'].shape[0]*temporal_resolution_hours, temporal_resolution_hours)\n",
    "        dataset = dataset.rename({\"time\": \"lead_time\"})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 49TB\n",
       "Dimensions:    (init_time: 3914, latitude: 721, level: 13, longitude: 1440,\n",
       "                time: 41)\n",
       "Coordinates:\n",
       "  * init_time  (init_time) datetime64[ns] 31kB 2020-09-30T12:00:00 ... 2025-0...\n",
       "  * latitude   (latitude) float32 3kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n",
       "  * level      (level) float64 104B 1e+03 925.0 850.0 700.0 ... 150.0 100.0 50.0\n",
       "  * longitude  (longitude) float32 6kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n",
       "  * time       (time) datetime64[ns] 328B 2020-09-30T12:00:00 ... 2020-10-10T...\n",
       "Data variables: (12/13)\n",
       "    msl        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    r          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    sp         (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    t          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    t2         (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    tcwv       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    ...         ...\n",
       "    u10        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    u100       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    v          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    v10        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    v100       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    z          (init_time, time, level, latitude, longitude) float32 9TB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-597b9458-969e-4608-8b4f-291cc47e2adf' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-597b9458-969e-4608-8b4f-291cc47e2adf' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>init_time</span>: 3914</li><li><span class='xr-has-index'>latitude</span>: 721</li><li><span class='xr-has-index'>level</span>: 13</li><li><span class='xr-has-index'>longitude</span>: 1440</li><li><span class='xr-has-index'>time</span>: 41</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-d93f3d52-b687-4ae2-a918-bcffeee2b1c7' class='xr-section-summary-in' type='checkbox'  checked><label for='section-d93f3d52-b687-4ae2-a918-bcffeee2b1c7' class='xr-section-summary' >Coordinates: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>init_time</span></div><div class='xr-var-dims'>(init_time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-09-30T12:00:00 ... 2025-03-...</div><input id='attrs-568648c8-0e0a-4f75-ba5c-68ae7663aa81' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-568648c8-0e0a-4f75-ba5c-68ae7663aa81' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1d21f277-885b-449e-9587-c32440126616' class='xr-var-data-in' type='checkbox'><label for='data-1d21f277-885b-449e-9587-c32440126616' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>_FillValue :</span></dt><dd>1970-01-01T00:00:00.000000000</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-09-30T12:00:00.000000000&#x27;, &#x27;2020-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-01T12:00:00.000000000&#x27;, ..., &#x27;2025-03-01T12:00:00.000000000&#x27;,\n",
       "       &#x27;2025-03-02T00:00:00.000000000&#x27;, &#x27;2025-03-02T12:00:00.000000000&#x27;],\n",
       "      shape=(3914,), dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>latitude</span></div><div class='xr-var-dims'>(latitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>90.0 89.75 89.5 ... -89.75 -90.0</div><input id='attrs-001680d3-cddc-4e30-9bc5-d5bda85c4491' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-001680d3-cddc-4e30-9bc5-d5bda85c4491' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-fecf40d8-92b4-46f7-8da1-6715e9156d94' class='xr-var-data-in' type='checkbox'><label for='data-fecf40d8-92b4-46f7-8da1-6715e9156d94' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>units :</span></dt><dd>degree</dd></dl></div><div class='xr-var-data'><pre>array([ 90.  ,  89.75,  89.5 , ..., -89.5 , -89.75, -90.  ],\n",
       "      shape=(721,), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>level</span></div><div class='xr-var-dims'>(level)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1e+03 925.0 850.0 ... 100.0 50.0</div><input id='attrs-2b7dc830-7554-4d25-b45c-3c1b39b0afb9' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-2b7dc830-7554-4d25-b45c-3c1b39b0afb9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ebfb536b-6335-472a-81c7-82390dd72a33' class='xr-var-data-in' type='checkbox'><label for='data-ebfb536b-6335-472a-81c7-82390dd72a33' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Isobaric surfaces</dd><dt><span>units :</span></dt><dd>hPa</dd></dl></div><div class='xr-var-data'><pre>array([1000.,  925.,  850.,  700.,  600.,  500.,  400.,  300.,  250.,  200.,\n",
       "        150.,  100.,   50.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>longitude</span></div><div class='xr-var-dims'>(longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 0.25 0.5 ... 359.2 359.5 359.8</div><input id='attrs-7bc64248-43cb-4fe2-9678-3ea136be2305' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-7bc64248-43cb-4fe2-9678-3ea136be2305' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ea550d4c-9895-4059-8b22-a3ee2bd5aa72' class='xr-var-data-in' type='checkbox'><label for='data-ea550d4c-9895-4059-8b22-a3ee2bd5aa72' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>units :</span></dt><dd>degree</dd></dl></div><div class='xr-var-data'><pre>array([0.0000e+00, 2.5000e-01, 5.0000e-01, ..., 3.5925e+02, 3.5950e+02,\n",
       "       3.5975e+02], shape=(1440,), dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2020-09-30T12:00:00 ... 2020-10-...</div><input id='attrs-3537ba5c-ddb0-4db5-a56a-601652f2683c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-3537ba5c-ddb0-4db5-a56a-601652f2683c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d94d36fb-448d-4816-b0e0-601217ecc0f4' class='xr-var-data-in' type='checkbox'><label for='data-d94d36fb-448d-4816-b0e0-601217ecc0f4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Date and Time</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;2020-09-30T12:00:00.000000000&#x27;, &#x27;2020-09-30T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-01T00:00:00.000000000&#x27;, &#x27;2020-10-01T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-01T12:00:00.000000000&#x27;, &#x27;2020-10-01T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-02T00:00:00.000000000&#x27;, &#x27;2020-10-02T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-02T12:00:00.000000000&#x27;, &#x27;2020-10-02T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-03T00:00:00.000000000&#x27;, &#x27;2020-10-03T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-03T12:00:00.000000000&#x27;, &#x27;2020-10-03T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-04T00:00:00.000000000&#x27;, &#x27;2020-10-04T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-04T12:00:00.000000000&#x27;, &#x27;2020-10-04T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-05T00:00:00.000000000&#x27;, &#x27;2020-10-05T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-05T12:00:00.000000000&#x27;, &#x27;2020-10-05T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-06T00:00:00.000000000&#x27;, &#x27;2020-10-06T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-06T12:00:00.000000000&#x27;, &#x27;2020-10-06T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-07T00:00:00.000000000&#x27;, &#x27;2020-10-07T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-07T12:00:00.000000000&#x27;, &#x27;2020-10-07T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-08T00:00:00.000000000&#x27;, &#x27;2020-10-08T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-08T12:00:00.000000000&#x27;, &#x27;2020-10-08T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-09T00:00:00.000000000&#x27;, &#x27;2020-10-09T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-09T12:00:00.000000000&#x27;, &#x27;2020-10-09T18:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-10T00:00:00.000000000&#x27;, &#x27;2020-10-10T06:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-10T12:00:00.000000000&#x27;], dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-709d063c-22bf-4518-99e8-dd74c897efe1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-709d063c-22bf-4518-99e8-dd74c897efe1' class='xr-section-summary' >Data variables: <span>(13)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>msl</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-2501a213-914b-491c-a789-ade1b32974c3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2501a213-914b-491c-a789-ade1b32974c3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-848f872b-7383-4ad1-9239-14a8458e91b2' class='xr-var-data-in' type='checkbox'><label for='data-848f872b-7383-4ad1-9239-14a8458e91b2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>r</span></div><div class='xr-var-dims'>(init_time, time, level, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-677e5256-ef9e-4875-86c4-514cb501e3e2' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-677e5256-ef9e-4875-86c4-514cb501e3e2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-927cd695-2dc7-4aee-a701-996274c82461' class='xr-var-data-in' type='checkbox'><label for='data-927cd695-2dc7-4aee-a701-996274c82461' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2165936834880 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>sp</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-d2eb033d-6323-48a8-903b-d17424a46ce7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-d2eb033d-6323-48a8-903b-d17424a46ce7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e0c0023f-8595-471a-801a-943bfdbb212b' class='xr-var-data-in' type='checkbox'><label for='data-e0c0023f-8595-471a-801a-943bfdbb212b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>t</span></div><div class='xr-var-dims'>(init_time, time, level, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-1b10baae-16e5-4cde-b7fd-8cad3e07c2f0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-1b10baae-16e5-4cde-b7fd-8cad3e07c2f0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b422e8ed-7ae3-4fc0-9115-7b4040334354' class='xr-var-data-in' type='checkbox'><label for='data-b422e8ed-7ae3-4fc0-9115-7b4040334354' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2165936834880 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>t2</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-c1b7c206-41c6-418e-90d2-913a338e3d5f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c1b7c206-41c6-418e-90d2-913a338e3d5f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-de44fa6f-faaa-4e1b-8527-9dab76adbbe7' class='xr-var-data-in' type='checkbox'><label for='data-de44fa6f-faaa-4e1b-8527-9dab76adbbe7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>tcwv</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a22a2560-f181-4c32-94a8-5a83341d8198' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a22a2560-f181-4c32-94a8-5a83341d8198' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4fcdd28d-d747-43c2-8a8c-05100a292629' class='xr-var-data-in' type='checkbox'><label for='data-4fcdd28d-d747-43c2-8a8c-05100a292629' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>u</span></div><div class='xr-var-dims'>(init_time, time, level, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e63acd16-c94c-4a97-819e-f450214b31c4' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e63acd16-c94c-4a97-819e-f450214b31c4' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4870ae39-fb29-4961-9086-471e718b0f7b' class='xr-var-data-in' type='checkbox'><label for='data-4870ae39-fb29-4961-9086-471e718b0f7b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2165936834880 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>u10</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-f14e0d5f-a23b-4290-9455-065cf507d017' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f14e0d5f-a23b-4290-9455-065cf507d017' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d948881e-1c02-4b6e-8ed5-568decb3d040' class='xr-var-data-in' type='checkbox'><label for='data-d948881e-1c02-4b6e-8ed5-568decb3d040' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>u100</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e95debf0-a1c5-496a-8082-55ac8409874b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e95debf0-a1c5-496a-8082-55ac8409874b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-efd410c7-c3c6-40fa-b181-ec0b6b5e2f84' class='xr-var-data-in' type='checkbox'><label for='data-efd410c7-c3c6-40fa-b181-ec0b6b5e2f84' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v</span></div><div class='xr-var-dims'>(init_time, time, level, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-86e8124a-0034-43cd-8ee0-412cbb76d2cb' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-86e8124a-0034-43cd-8ee0-412cbb76d2cb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6c296f84-ea4d-4812-b5dd-d701c73ab7ad' class='xr-var-data-in' type='checkbox'><label for='data-6c296f84-ea4d-4812-b5dd-d701c73ab7ad' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2165936834880 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v10</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-3db62e4c-de87-44e3-b5c6-9cbd986f7890' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3db62e4c-de87-44e3-b5c6-9cbd986f7890' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e3a5df97-10e5-4831-bb6d-919dafc7b45c' class='xr-var-data-in' type='checkbox'><label for='data-e3a5df97-10e5-4831-bb6d-919dafc7b45c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>v100</span></div><div class='xr-var-dims'>(init_time, time, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-0ee33929-d44d-48ee-a25b-b75518014dad' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0ee33929-d44d-48ee-a25b-b75518014dad' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3be8cf02-33f5-40e1-970b-50dddb42c38b' class='xr-var-data-in' type='checkbox'><label for='data-3be8cf02-33f5-40e1-970b-50dddb42c38b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[166610525760 values with dtype=float32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>z</span></div><div class='xr-var-dims'>(init_time, time, level, latitude, longitude)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e18b6570-7cb4-4f25-9636-bae6420aba90' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e18b6570-7cb4-4f25-9636-bae6420aba90' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2fb7e4c0-1640-4452-9f3b-e3720a3d832d' class='xr-var-data-in' type='checkbox'><label for='data-2fb7e4c0-1640-4452-9f3b-e3720a3d832d' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2165936834880 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1f3d0d59-2790-4a06-84aa-2f7b7418393c' class='xr-section-summary-in' type='checkbox'  ><label for='section-1f3d0d59-2790-4a06-84aa-2f7b7418393c' class='xr-section-summary' >Indexes: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>init_time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-3f3c0dd4-e955-4288-87c5-f28903aa2744' class='xr-index-data-in' type='checkbox'/><label for='index-3f3c0dd4-e955-4288-87c5-f28903aa2744' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2020-09-30 12:00:00&#x27;, &#x27;2020-10-01 00:00:00&#x27;,\n",
       "               &#x27;2020-10-01 12:00:00&#x27;, &#x27;2020-10-02 00:00:00&#x27;,\n",
       "               &#x27;2020-10-02 12:00:00&#x27;, &#x27;2020-10-03 00:00:00&#x27;,\n",
       "               &#x27;2020-10-03 12:00:00&#x27;, &#x27;2020-10-04 00:00:00&#x27;,\n",
       "               &#x27;2020-10-04 12:00:00&#x27;, &#x27;2020-10-05 00:00:00&#x27;,\n",
       "               ...\n",
       "               &#x27;2025-02-26 00:00:00&#x27;, &#x27;2025-02-26 12:00:00&#x27;,\n",
       "               &#x27;2025-02-27 00:00:00&#x27;, &#x27;2025-02-27 12:00:00&#x27;,\n",
       "               &#x27;2025-02-28 00:00:00&#x27;, &#x27;2025-02-28 12:00:00&#x27;,\n",
       "               &#x27;2025-03-01 00:00:00&#x27;, &#x27;2025-03-01 12:00:00&#x27;,\n",
       "               &#x27;2025-03-02 00:00:00&#x27;, &#x27;2025-03-02 12:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;init_time&#x27;, length=3914, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>latitude</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-cb5efb8d-e0c1-4ac7-b9bd-e0e6a3c2c5c5' class='xr-index-data-in' type='checkbox'/><label for='index-cb5efb8d-e0c1-4ac7-b9bd-e0e6a3c2c5c5' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([  90.0,  89.75,   89.5,  89.25,   89.0,  88.75,   88.5,  88.25,   88.0,\n",
       "        87.75,\n",
       "       ...\n",
       "       -87.75,  -88.0, -88.25,  -88.5, -88.75,  -89.0, -89.25,  -89.5, -89.75,\n",
       "        -90.0],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;latitude&#x27;, length=721))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>level</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-371adef2-e558-495d-aceb-d564565d301e' class='xr-index-data-in' type='checkbox'/><label for='index-371adef2-e558-495d-aceb-d564565d301e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([1000.0,  925.0,  850.0,  700.0,  600.0,  500.0,  400.0,  300.0,  250.0,\n",
       "        200.0,  150.0,  100.0,   50.0],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;level&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>longitude</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-f98ebf9b-e6d8-4399-b7fd-ab11dc0b2ed2' class='xr-index-data-in' type='checkbox'/><label for='index-f98ebf9b-e6d8-4399-b7fd-ab11dc0b2ed2' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0.0,   0.25,    0.5,   0.75,    1.0,   1.25,    1.5,   1.75,    2.0,\n",
       "         2.25,\n",
       "       ...\n",
       "        357.5, 357.75,  358.0, 358.25,  358.5, 358.75,  359.0, 359.25,  359.5,\n",
       "       359.75],\n",
       "      dtype=&#x27;float32&#x27;, name=&#x27;longitude&#x27;, length=1440))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-741512e0-5055-41c3-b761-d436139df6c8' class='xr-index-data-in' type='checkbox'/><label for='index-741512e0-5055-41c3-b761-d436139df6c8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2020-09-30 12:00:00&#x27;, &#x27;2020-09-30 18:00:00&#x27;,\n",
       "               &#x27;2020-10-01 00:00:00&#x27;, &#x27;2020-10-01 06:00:00&#x27;,\n",
       "               &#x27;2020-10-01 12:00:00&#x27;, &#x27;2020-10-01 18:00:00&#x27;,\n",
       "               &#x27;2020-10-02 00:00:00&#x27;, &#x27;2020-10-02 06:00:00&#x27;,\n",
       "               &#x27;2020-10-02 12:00:00&#x27;, &#x27;2020-10-02 18:00:00&#x27;,\n",
       "               &#x27;2020-10-03 00:00:00&#x27;, &#x27;2020-10-03 06:00:00&#x27;,\n",
       "               &#x27;2020-10-03 12:00:00&#x27;, &#x27;2020-10-03 18:00:00&#x27;,\n",
       "               &#x27;2020-10-04 00:00:00&#x27;, &#x27;2020-10-04 06:00:00&#x27;,\n",
       "               &#x27;2020-10-04 12:00:00&#x27;, &#x27;2020-10-04 18:00:00&#x27;,\n",
       "               &#x27;2020-10-05 00:00:00&#x27;, &#x27;2020-10-05 06:00:00&#x27;,\n",
       "               &#x27;2020-10-05 12:00:00&#x27;, &#x27;2020-10-05 18:00:00&#x27;,\n",
       "               &#x27;2020-10-06 00:00:00&#x27;, &#x27;2020-10-06 06:00:00&#x27;,\n",
       "               &#x27;2020-10-06 12:00:00&#x27;, &#x27;2020-10-06 18:00:00&#x27;,\n",
       "               &#x27;2020-10-07 00:00:00&#x27;, &#x27;2020-10-07 06:00:00&#x27;,\n",
       "               &#x27;2020-10-07 12:00:00&#x27;, &#x27;2020-10-07 18:00:00&#x27;,\n",
       "               &#x27;2020-10-08 00:00:00&#x27;, &#x27;2020-10-08 06:00:00&#x27;,\n",
       "               &#x27;2020-10-08 12:00:00&#x27;, &#x27;2020-10-08 18:00:00&#x27;,\n",
       "               &#x27;2020-10-09 00:00:00&#x27;, &#x27;2020-10-09 06:00:00&#x27;,\n",
       "               &#x27;2020-10-09 12:00:00&#x27;, &#x27;2020-10-09 18:00:00&#x27;,\n",
       "               &#x27;2020-10-10 00:00:00&#x27;, &#x27;2020-10-10 06:00:00&#x27;,\n",
       "               &#x27;2020-10-10 12:00:00&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, freq=None))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-ed7f2536-46f3-4e63-b2e3-c26c053f9e15' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-ed7f2536-46f3-4e63-b2e3-c26c053f9e15' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 49TB\n",
       "Dimensions:    (init_time: 3914, latitude: 721, level: 13, longitude: 1440,\n",
       "                time: 41)\n",
       "Coordinates:\n",
       "  * init_time  (init_time) datetime64[ns] 31kB 2020-09-30T12:00:00 ... 2025-0...\n",
       "  * latitude   (latitude) float32 3kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n",
       "  * level      (level) float64 104B 1e+03 925.0 850.0 700.0 ... 150.0 100.0 50.0\n",
       "  * longitude  (longitude) float32 6kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n",
       "  * time       (time) datetime64[ns] 328B 2020-09-30T12:00:00 ... 2020-10-10T...\n",
       "Data variables: (12/13)\n",
       "    msl        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    r          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    sp         (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    t          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    t2         (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    tcwv       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    ...         ...\n",
       "    u10        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    u100       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    v          (init_time, time, level, latitude, longitude) float32 9TB ...\n",
       "    v10        (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    v100       (init_time, time, latitude, longitude) float32 666GB ...\n",
       "    z          (init_time, time, level, latitude, longitude) float32 9TB ..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = \"gs://extremeweatherbench\"\n",
    "store = from_url(bucket, skip_signature=True)\n",
    "\n",
    "[n for n in store.list().collect()]\n",
    "registry = ObjectStoreRegistry({bucket: store})\n",
    "storage_options = {\n",
    "    \"remote_protocol\": \"s3\",\n",
    "    \"remote_options\": {\"anon\": True},\n",
    "}  # options passed to fsspec\n",
    "kerchunk_ds = xr.open_dataset(\n",
    "    f\"{bucket}/FOUR_v200_GFS.parq\",\n",
    "    engine=\"kerchunk\",\n",
    "    storage_options=storage_options\n",
    ")\n",
    "kerchunk_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_forecast(forecast_dir: str, case_operator: CaseOperator, **kwargs):\n",
    "    forecast_ds = open_and_preprocess_forecast_dataset(forecast_dir,\n",
    "                                                       forecast_variables=case_operator.forecast_variables,\n",
    "                                                       forecast_variable_mapping=kwargs.get('forecast_variable_mapping', {}),\n",
    "                                                       forecast_storage_options=kwargs.get('forecast_storage_options', {'remote_protocol': 's3', 'remote_options': {'anon': True}}),\n",
    "                                                       forecast_chunks=kwargs.get('forecast_chunks', {'time': 48, 'latitude': 721, 'longitude': 1440}))\n",
    "    time_indices = utils.derive_indices_from_init_time_and_lead_time(forecast_ds, case_operator.case.start_date, case_operator.case.end_date)\n",
    "    forecast_ds_time_subset = forecast_ds.isel(init_time=np.unique(time_indices))\n",
    "    forecast_ds = case_operator.case.location.mask(forecast_ds_time_subset,drop=True)\n",
    "    return forecast_ds\n",
    "\n",
    "class ExtremeWeatherBench:\n",
    "    def run(self, events: list[EventType], forecast_dir: str, cache_dir: Optional[str] = None, *args, **kwargs):\n",
    "        '''Runs the workflow in the order of the event operators and cases inside the event operators.'''\n",
    "\n",
    "        for event in events:\n",
    "            case_operators = event.build_case_operators(observation_storage_options=kwargs.get('observation_storage_options', {'remote_protocol': 's3', 'remote_options': {'anon': True}}), observation_variable_mapping=kwargs.get('observation_variable_mapping', {'anon': True}))\n",
    "            \n",
    "        for case_operator in case_operators:\n",
    "            observation_ds, forecast_ds = self.build_datasets(case_operator, forecast_dir, *args, **kwargs)\n",
    "            return observation_ds, forecast_ds\n",
    "\n",
    "    def build_datasets(self, case_operator: CaseOperator, forecast_dir: str, **kwargs):\n",
    "        observation_ds = case_operator.build_observations(**kwargs)\n",
    "        forecast_ds = self.build_forecast(case_operator, forecast_dir, **kwargs)\n",
    "        return observation_ds, forecast_ds\n",
    "\n",
    "\n",
    "    \n",
    "    def build_forecast(self, case_operator: CaseOperator, forecast_dir: str, **kwargs):\n",
    "        pre_derived_forecast_ds = _build_forecast(forecast_dir, case_operator, **kwargs)\n",
    "        derived_forecast_ds = maybe_derive_variables(pre_derived_forecast_ds, case_operator, variables=case_operator.forecast_variables)\n",
    "        return derived_forecast_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test pph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def practically_perfect_hindcast(\n",
    "    ds: xr.Dataset,\n",
    "    resolution: float = 0.25,\n",
    "    # TODO: add report type back in\n",
    "    # report_type: Union[Literal[\"all\"], list[Literal[\"tor\", \"hail\", \"wind\"]]] = \"all\",\n",
    "    sigma: float = 1.5,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Compute the Practically Perfect Hindcast (PPH) using storm report data using latitude/longitude grid spacing\n",
    "    instead of the NCEP 212 Eta Lambert Conformal projection; based on the method described in Hitchens et al 2013,\n",
    "    https://doi.org/10.1175/WAF-D-12-00113.1\n",
    "\n",
    "    Args:\n",
    "        ds: An xarray Dataset containing the storm report data as a sparse (COO) array.\n",
    "        resolution: The resolution of the grid in degrees to use. Default is 0.25 degrees.\n",
    "        sigma: The standard deviation of the gaussian filter to use. Default is 1.5.\n",
    "    Returns:\n",
    "        pph: An xarray Dataset containing the PPH and storm report data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a global grid with 0.25 degree resolution (721 x 1440)\n",
    "    min_lat_fixed = -90.0  # Start at -90 degrees\n",
    "    max_lat_fixed = 90.0  # End at 90 degrees\n",
    "    min_lon_fixed = 0.0  # Start at 0 degrees\n",
    "    max_lon_fixed = 359.75  # End at 359.75 degrees (360-0.25)\n",
    "\n",
    "    # Create the grid coordinates\n",
    "    grid_lats = np.arange(min_lat_fixed, max_lat_fixed + resolution, resolution)\n",
    "    grid_lons = np.arange(min_lon_fixed, max_lon_fixed + resolution, resolution)\n",
    "\n",
    "    # Create target coordinates for regridding\n",
    "    target_coords = {\n",
    "        \"latitude\": xr.DataArray(grid_lats, dims=[\"latitude\"]),\n",
    "        \"longitude\": xr.DataArray(grid_lons, dims=[\"longitude\"]),\n",
    "    }\n",
    "\n",
    "    # Regrid the sparse dataset to the fixed global grid\n",
    "    # First, ensure longitude is in 0-360 range\n",
    "    if \"longitude\" in ds.coords:\n",
    "        ds = ds.assign_coords(longitude=utils.convert_longitude_to_360(ds.longitude))\n",
    "\n",
    "    # Interpolate the sparse data to the target grid\n",
    "    regridded_ds = ds.interp(\n",
    "        latitude=target_coords[\"latitude\"],\n",
    "        longitude=target_coords[\"longitude\"],\n",
    "        method=\"nearest\",  # Use nearest neighbor for sparse data\n",
    "    )\n",
    "\n",
    "    # Fill NaN values with 0 for the reports\n",
    "    if \"reports\" in regridded_ds.data_vars:\n",
    "        regridded_ds[\"reports\"] = regridded_ds[\"reports\"].fillna(0)\n",
    "\n",
    "    # Apply gaussian smoothing to the regridded data\n",
    "    if \"reports\" in regridded_ds.data_vars:\n",
    "        reports_data = regridded_ds[\"reports\"].values\n",
    "        smoothed_reports = gaussian_filter(reports_data, sigma=sigma)\n",
    "        regridded_ds[\"practically_perfect\"] = xr.DataArray(\n",
    "            smoothed_reports,\n",
    "            dims=[\"latitude\", \"longitude\"],\n",
    "            coords={\"latitude\": grid_lats, \"longitude\": grid_lons},\n",
    "        )\n",
    "\n",
    "    return regridded_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Event Operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_yaml = utils.read_event_yaml('/Users/taylor/code/ExtremeWeatherBench/src/extremeweatherbench/data/events.yaml')\n",
    "test_yaml = {'cases': [case_yaml['cases'][0]]}\n",
    "test_heat_wave = HeatWave(case_metadata=test_yaml)\n",
    "# case_operator = test_heat_wave.build_case_operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_dir = 'gs://extremeweatherbench/FOUR_v200_GFS.parq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<xarray.Dataset> Size: 503kB\n",
       "  Dimensions:                  (time: 313, latitude: 20, longitude: 20)\n",
       "  Coordinates:\n",
       "    * latitude                 (latitude) float32 80B 50.0 49.75 ... 45.5 45.25\n",
       "    * longitude                (longitude) float32 80B 235.2 235.5 ... 239.8 240.0\n",
       "    * time                     (time) datetime64[ns] 3kB 2021-06-20 ... 2021-07-03\n",
       "  Data variables:\n",
       "      surface_air_temperature  (time, latitude, longitude) float32 501kB dask.array<chunksize=(48, 20, 20), meta=np.ndarray>\n",
       "  Attributes:\n",
       "      last_updated:           2025-08-01 01:47:15.698116+00:00\n",
       "      valid_time_start:       1940-01-01\n",
       "      valid_time_stop:        2025-04-30\n",
       "      valid_time_stop_era5t:  2025-07-26],\n",
       " <xarray.Dataset> Size: 3MB\n",
       " Dimensions:                  (init_time: 45, lead_time: 41, latitude: 20,\n",
       "                               longitude: 20)\n",
       " Coordinates:\n",
       "   * init_time                (init_time) datetime64[ns] 360B 2021-06-10T12:00...\n",
       "   * latitude                 (latitude) float32 80B 50.0 49.75 ... 45.5 45.25\n",
       "   * longitude                (longitude) float32 80B 235.2 235.5 ... 239.8 240.0\n",
       "   * lead_time                (lead_time) float64 328B 0.0 6.0 ... 234.0 240.0\n",
       " Data variables:\n",
       "     surface_air_temperature  (init_time, lead_time, latitude, longitude) float32 3MB dask.array<chunksize=(1, 1, 20, 20), meta=np.ndarray>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ewb = ExtremeWeatherBench()\n",
    "test_ewb.run(\n",
    "    events=[test_heat_wave],\n",
    "    forecast_dir=forecast_dir,\n",
    "    storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}}, \n",
    "    chunks={'time': 48, 'latitude': 721, 'longitude': 1440}, \n",
    "    observation_variable_mapping={'2m_temperature':'surface_air_temperature'}, \n",
    "    forecast_variable_mapping={'t2':'surface_air_temperature'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# future approach\n",
    "# test_ewb.run(\n",
    "#     events=[test_heat_wave, severe],\n",
    "#     forecast_dir=forecast_dir,\n",
    "#     forecast_storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}}, \n",
    "#     chunks={'time': 48, 'latitude': 721, 'longitude': 1440}, \n",
    "#     observation_variable_mapping={'2m_temperature':'surface_air_temperature'}, \n",
    "#     forecast_variable_mapping={'t2':'surface_air_temperature'},\n",
    "#     cache_dir=cache_dir,\n",
    "#     output_dir=output_dir\n",
    "# )\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "# for n in tqdm(test_heat_wave_event_operator.pre_composed_case_operators):\n",
    "#     print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<xarray.Dataset> Size: 309kB\n",
       "  Dimensions:                       (valid_time: 197, latitude: 176,\n",
       "                                     longitude: 211)\n",
       "  Coordinates:\n",
       "    * valid_time                    (valid_time) datetime64[ns] 2kB 2024-07-13 ...\n",
       "    * latitude                      (latitude) float64 1kB 37.92 38.18 ... 48.83\n",
       "    * longitude                     (longitude) float64 2kB -113.0 ... -67.87\n",
       "  Data variables:\n",
       "      report_type                   (valid_time, latitude, longitude) object 3kB <COO: nnz=249, fill_value=nan>\n",
       "      Scale                         (valid_time, latitude, longitude) object 3kB <COO: nnz=249, fill_value=nan>\n",
       "      practically_perfect_hindcast  (latitude, longitude) float64 297kB nan ......],\n",
       " <xarray.Dataset> Size: 5GB\n",
       " Dimensions:                              (init_time: 21, lead_time: 41,\n",
       "                                           latitude: 100, longitude: 200,\n",
       "                                           level: 13)\n",
       " Coordinates:\n",
       "   * init_time                            (init_time) datetime64[ns] 168B 2024...\n",
       "   * latitude                             (latitude) float32 400B 49.0 ... 24.25\n",
       "   * level                                (level) float64 104B 1e+03 ... 50.0\n",
       "   * longitude                            (longitude) float32 800B 245.2 ... 2...\n",
       "   * lead_time                            (lead_time) float64 328B 0.0 ... 240.0\n",
       " Data variables:\n",
       "     mean_sea_level_pressure              (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>\n",
       "     relative_humidity                    (init_time, lead_time, level, latitude, longitude) float32 895MB dask.array<chunksize=(1, 1, 13, 100, 200), meta=np.ndarray>\n",
       "     surface_pressure                     (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>\n",
       "     surface_air_temperature              (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>\n",
       "     surface_eastward_wind                (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>\n",
       "     surface_northward_wind               (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>\n",
       "     air_temperature                      (init_time, lead_time, level, latitude, longitude) float32 895MB dask.array<chunksize=(1, 1, 13, 100, 200), meta=np.ndarray>\n",
       "     eastward_wind                        (init_time, lead_time, level, latitude, longitude) float32 895MB dask.array<chunksize=(1, 1, 13, 100, 200), meta=np.ndarray>\n",
       "     northward_wind                       (init_time, lead_time, level, latitude, longitude) float32 895MB dask.array<chunksize=(1, 1, 13, 100, 200), meta=np.ndarray>\n",
       "     geopotential_height                  (init_time, lead_time, level, latitude, longitude) float32 895MB dask.array<chunksize=(1, 1, 13, 100, 200), meta=np.ndarray>\n",
       "     craven_significant_severe_parameter  (init_time, lead_time, latitude, longitude) float32 69MB dask.array<chunksize=(1, 1, 100, 200), meta=np.ndarray>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_yaml = {'cases': [[n for n in case_yaml['cases'] if n['event_type']=='severe_convection'][0]]}\n",
    "severe = SevereConvection(case_metadata=test_yaml)\n",
    "ewb = ExtremeWeatherBench()\n",
    "ewb.run(    \n",
    "    events=[severe],\n",
    "    forecast_dir=forecast_dir,\n",
    "    storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}}, \n",
    "    chunks={'time': 48, 'latitude': 721, 'longitude': 1440}, \n",
    "    observation_variable_mapping=rs.ERA5_MAPPING, \n",
    "    forecast_variable_mapping={'msl':'mean_sea_level_pressure',\n",
    " 'r':'relative_humidity',\n",
    " 'sp':'surface_pressure',\n",
    " 't2':'surface_air_temperature',\n",
    " 'u10':'surface_eastward_wind',\n",
    " 'v10':'surface_northward_wind',\n",
    " 't':'air_temperature',\n",
    " 'u':'eastward_wind',\n",
    " 'v':'northward_wind',\n",
    " 'z':'geopotential_height'})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the EventOperator class\n",
    "simple_event_operator = EventOperator(events=[heat_waves, severe])\n",
    "ewb = ExtremeWeatherBench(simple_event_operator, forecast_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventOperator(events=[<__main__.HeatWave object at 0x1198d6650>, <__main__.SevereConvection object at 0x1198d69e0>], pre_composed_metrics={'heat_wave': [<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], 'severe_convection': [<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>]}, pre_composed_observations={'heat_wave': [<class '__main__.ERA5'>], 'severe_convection': [<class '__main__.LSR'>]}, pre_composed_forecast_variables={'heat_wave': ['surface_air_temperature'], 'severe_convection': [<class '__main__.CravenSignificantSevereParameter'>, 'air_temperature', 'dewpoint_temperature', 'relative_humidity', 'eastward_wind', 'northward_wind', 'surface_eastward_wind', 'surface_northward_wind', 'air_temperature', 'dewpoint_temperature', 'relative_humidity', 'eastward_wind', 'northward_wind', 'surface_eastward_wind', 'surface_northward_wind']}, pre_composed_observation_variables={'heat_wave': ['surface_air_temperature'], 'severe_convection': [<class '__main__.PracticallyPerfectHindcast'>, 'report_type', 'report_type']}, pre_composed_case_operators=[CaseOperator(case=IndividualCase(case_id_number=1, title='2021 Pacific Northwest', start_date=datetime.datetime(2021, 6, 20, 0, 0), end_date=datetime.datetime(2021, 7, 3, 0, 0), location=CenteredRegion(latitude=47.6062, longitude=237.6679, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=2, title='2022 Upper Midwest', start_date=datetime.datetime(2022, 5, 7, 0, 0), end_date=datetime.datetime(2022, 5, 17, 0, 0), location=CenteredRegion(latitude=41.8781, longitude=272.3702, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=3, title='2022 California', start_date=datetime.datetime(2022, 6, 7, 0, 0), end_date=datetime.datetime(2022, 6, 15, 0, 0), location=CenteredRegion(latitude=34.0522, longitude=241.7563, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=4, title='2022 Texas', start_date=datetime.datetime(2022, 6, 30, 0, 0), end_date=datetime.datetime(2022, 7, 18, 0, 0), location=CenteredRegion(latitude=32.7767, longitude=263.203, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=5, title='2023 Pacific Northwest', start_date=datetime.datetime(2023, 5, 10, 0, 0), end_date=datetime.datetime(2023, 5, 23, 0, 0), location=CenteredRegion(latitude=47.6062, longitude=237.6679, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=6, title='2022 Mid-Atlantic', start_date=datetime.datetime(2022, 5, 17, 0, 0), end_date=datetime.datetime(2022, 5, 24, 0, 0), location=CenteredRegion(latitude=39.2904, longitude=283.38779999999997, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=7, title='2023 Australia', start_date=datetime.datetime(2023, 11, 18, 0, 0), end_date=datetime.datetime(2023, 11, 28, 0, 0), location=CenteredRegion(latitude=-31.9505, longitude=115.8605, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=8, title='2023 Ireland', start_date=datetime.datetime(2023, 9, 2, 0, 0), end_date=datetime.datetime(2023, 9, 13, 0, 0), location=CenteredRegion(latitude=53.1424, longitude=352.3079, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=9, title='2023 Italy', start_date=datetime.datetime(2023, 7, 7, 0, 0), end_date=datetime.datetime(2023, 7, 27, 0, 0), location=CenteredRegion(latitude=41.9028, longitude=12.4964, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=10, title='2023 SW Europe', start_date=datetime.datetime(2023, 8, 17, 0, 0), end_date=datetime.datetime(2023, 8, 28, 0, 0), location=CenteredRegion(latitude=40.4637, longitude=356.2508, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=11, title='2023 South America', start_date=datetime.datetime(2023, 7, 29, 0, 0), end_date=datetime.datetime(2023, 8, 4, 0, 0), location=CenteredRegion(latitude=-34.6037, longitude=301.6184, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=12, title='2023 China (Shanghai)', start_date=datetime.datetime(2023, 5, 24, 0, 0), end_date=datetime.datetime(2023, 6, 1, 0, 0), location=CenteredRegion(latitude=31.2304, longitude=121.4737, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=13, title='2023 China (Yunnan Province)', start_date=datetime.datetime(2023, 4, 14, 0, 0), end_date=datetime.datetime(2023, 4, 23, 0, 0), location=CenteredRegion(latitude=25.0458, longitude=102.71, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=14, title='2023 Algeria', start_date=datetime.datetime(2023, 7, 5, 0, 0), end_date=datetime.datetime(2023, 7, 27, 0, 0), location=CenteredRegion(latitude=36.7372, longitude=3.0869, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=15, title='2023 Iberian Peninsula', start_date=datetime.datetime(2023, 4, 22, 0, 0), end_date=datetime.datetime(2023, 5, 1, 0, 0), location=CenteredRegion(latitude=41.1496, longitude=352.389, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=16, title='2023 Gibraltar', start_date=datetime.datetime(2023, 4, 22, 0, 0), end_date=datetime.datetime(2023, 5, 3, 0, 0), location=CenteredRegion(latitude=36.1408, longitude=354.64639999999997, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=17, title='2023 India', start_date=datetime.datetime(2023, 2, 15, 0, 0), end_date=datetime.datetime(2023, 3, 1, 0, 0), location=CenteredRegion(latitude=28.6139, longitude=77.209, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=18, title='2021 Western Russia', start_date=datetime.datetime(2021, 6, 18, 0, 0), end_date=datetime.datetime(2021, 6, 30, 0, 0), location=CenteredRegion(latitude=55.7558, longitude=37.6173, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=19, title='2022 Germany', start_date=datetime.datetime(2022, 12, 23, 0, 0), end_date=datetime.datetime(2022, 12, 31, 0, 0), location=CenteredRegion(latitude=52.52, longitude=13.405, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=20, title='2022 UK (August)', start_date=datetime.datetime(2022, 8, 8, 0, 0), end_date=datetime.datetime(2022, 8, 16, 0, 0), location=CenteredRegion(latitude=51.5074, longitude=359.8722, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=21, title='2022 UK (July)', start_date=datetime.datetime(2022, 7, 15, 0, 0), end_date=datetime.datetime(2022, 7, 23, 0, 0), location=CenteredRegion(latitude=51.5074, longitude=359.8722, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=22, title='2022 France', start_date=datetime.datetime(2022, 6, 9, 0, 0), end_date=datetime.datetime(2022, 6, 21, 0, 0), location=CenteredRegion(latitude=43.4832, longitude=358.4414, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=23, title='2022 Japan', start_date=datetime.datetime(2022, 6, 20, 0, 0), end_date=datetime.datetime(2022, 7, 5, 0, 0), location=CenteredRegion(latitude=35.6895, longitude=139.6917, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=24, title='2022 India', start_date=datetime.datetime(2022, 4, 24, 0, 0), end_date=datetime.datetime(2022, 5, 4, 0, 0), location=CenteredRegion(latitude=28.2769, longitude=68.4376, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=25, title='2022 East Antarctica', start_date=datetime.datetime(2022, 3, 12, 0, 0), end_date=datetime.datetime(2022, 3, 26, 0, 0), location=CenteredRegion(latitude=-75.1, longitude=123.35, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=26, title='2022 West Australia', start_date=datetime.datetime(2022, 1, 15, 0, 0), end_date=datetime.datetime(2022, 1, 25, 0, 0), location=CenteredRegion(latitude=-31.9505, longitude=115.8605, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=27, title='2021 Canada Plains', start_date=datetime.datetime(2021, 5, 30, 0, 0), end_date=datetime.datetime(2021, 6, 9, 0, 0), location=CenteredRegion(latitude=49.0, longitude=262.43330000000003, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=28, title='2021 New Zealand', start_date=datetime.datetime(2021, 1, 12, 18, 0), end_date=datetime.datetime(2021, 1, 17, 18, 0), location=CenteredRegion(latitude=-43.8983, longitude=171.731, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=29, title='2020 Australia', start_date=datetime.datetime(2020, 11, 25, 0, 0), end_date=datetime.datetime(2020, 11, 30, 0, 0), location=CenteredRegion(latitude=-33.8245, longitude=150.9448, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=72, title='May 2024 Texas', start_date=datetime.datetime(2024, 5, 25, 0, 0), end_date=datetime.datetime(2024, 5, 28, 0, 0), location=CenteredRegion(latitude=25.9017, longitude=262.50260000000003, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=73, title='June 2024 Northeast US', start_date=datetime.datetime(2024, 6, 17, 0, 0), end_date=datetime.datetime(2024, 6, 22, 0, 0), location=CenteredRegion(latitude=41.8781, longitude=286.771, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=74, title='July 2024 Southwest US', start_date=datetime.datetime(2024, 7, 4, 0, 0), end_date=datetime.datetime(2024, 7, 8, 0, 0), location=CenteredRegion(latitude=33.7701, longitude=243.78539999999998, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=75, title='July 2024 Northeast US', start_date=datetime.datetime(2024, 7, 7, 0, 0), end_date=datetime.datetime(2024, 7, 10, 0, 0), location=CenteredRegion(latitude=40.7128, longitude=285.994, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=76, title='July 2024 Mid-Atlantic US', start_date=datetime.datetime(2024, 7, 15, 0, 0), end_date=datetime.datetime(2024, 7, 20, 0, 0), location=CenteredRegion(latitude=39.9526, longitude=284.8348, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=77, title='August 2024 Midwest US', start_date=datetime.datetime(2024, 8, 25, 0, 0), end_date=datetime.datetime(2024, 8, 31, 0, 0), location=CenteredRegion(latitude=40.1106, longitude=271.79269999999997, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=78, title='July 2024 Antarctica', start_date=datetime.datetime(2024, 7, 1, 0, 0), end_date=datetime.datetime(2024, 7, 31, 0, 0), location=CenteredRegion(latitude=-75.0, longitude=15.0, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=79, title='August 2024 Canada', start_date=datetime.datetime(2024, 8, 9, 0, 0), end_date=datetime.datetime(2024, 8, 11, 0, 0), location=CenteredRegion(latitude=67.0, longitude=248.0, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=80, title='August 2024 Australia', start_date=datetime.datetime(2024, 8, 22, 0, 0), end_date=datetime.datetime(2024, 8, 30, 0, 0), location=CenteredRegion(latitude=-20.0, longitude=120.0, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=81, title='July/August 2024 Japan', start_date=datetime.datetime(2024, 7, 25, 0, 0), end_date=datetime.datetime(2024, 8, 5, 0, 0), location=CenteredRegion(latitude=36.0, longitude=138.0, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=82, title='June 2024 Saudi Arabia', start_date=datetime.datetime(2024, 6, 16, 0, 0), end_date=datetime.datetime(2024, 6, 18, 0, 0), location=CenteredRegion(latitude=24.0, longitude=45.0, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=83, title='August 2024 Europe', start_date=datetime.datetime(2024, 8, 10, 0, 0), end_date=datetime.datetime(2024, 8, 15, 0, 0), location=CenteredRegion(latitude=48.3794, longitude=10.8978, bounding_box_degrees=10), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=84, title='July 2024 Ukraine', start_date=datetime.datetime(2024, 7, 12, 0, 0), end_date=datetime.datetime(2024, 7, 16, 0, 0), location=CenteredRegion(latitude=50.4501, longitude=30.5234, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=85, title='June 2024 Europe', start_date=datetime.datetime(2024, 6, 20, 0, 0), end_date=datetime.datetime(2024, 6, 30, 0, 0), location=CenteredRegion(latitude=52.3676, longitude=4.9041, bounding_box_degrees=6), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=86, title='May 2024 Central Mexico', start_date=datetime.datetime(2024, 5, 23, 0, 0), end_date=datetime.datetime(2024, 5, 31, 0, 0), location=CenteredRegion(latitude=19.4326, longitude=260.8668, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=87, title='May 2024 Pakistan/India', start_date=datetime.datetime(2024, 5, 23, 0, 0), end_date=datetime.datetime(2024, 5, 31, 0, 0), location=CenteredRegion(latitude=34.0, longitude=76.0, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=88, title='August 2023 Chile', start_date=datetime.datetime(2023, 8, 1, 0, 0), end_date=datetime.datetime(2023, 8, 3, 0, 0), location=CenteredRegion(latitude=-33.4489, longitude=289.3307, bounding_box_degrees=5), event_type='heat_wave', data_vars=None, cross_listed=None), metrics=[<class '__main__.MaximumMAE'>, <class '__main__.MaxMinMAE'>, <class '__main__.RegionalRMSE'>, <class '__main__.OnsetME'>, <class '__main__.DurationME'>], observations=[<class '__main__.ERA5'>]), CaseOperator(case=IndividualCase(case_id_number=36, title='July 2024 South Dakota', start_date=datetime.datetime(2024, 7, 13, 0, 0), end_date=datetime.datetime(2024, 7, 14, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=49.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=37, title='July 2024 Chicago', start_date=datetime.datetime(2024, 7, 14, 0, 0), end_date=datetime.datetime(2024, 7, 16, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=49.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=38, title='July 2024 New York', start_date=datetime.datetime(2024, 7, 16, 0, 0), end_date=datetime.datetime(2024, 7, 17, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=49.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=39, title='May 2024 Wisconsin', start_date=datetime.datetime(2024, 5, 18, 0, 0), end_date=datetime.datetime(2024, 5, 19, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=40, title='May 2024 Kansas', start_date=datetime.datetime(2024, 5, 19, 0, 0), end_date=datetime.datetime(2024, 5, 20, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=41, title='May 2024 Iowa + Nebraska', start_date=datetime.datetime(2024, 5, 20, 0, 0), end_date=datetime.datetime(2024, 5, 21, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=42, title='May 2024 Iowa + Wisconsin', start_date=datetime.datetime(2024, 5, 21, 0, 0), end_date=datetime.datetime(2024, 5, 22, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=43, title='May 2024 Texas', start_date=datetime.datetime(2024, 5, 22, 0, 0), end_date=datetime.datetime(2024, 5, 23, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=44, title='May 2024 Iowa + Nebraska 2', start_date=datetime.datetime(2024, 5, 23, 0, 0), end_date=datetime.datetime(2024, 5, 24, 0, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=45, title='April 2024 Oklahoma', start_date=datetime.datetime(2024, 4, 25, 12, 0), end_date=datetime.datetime(2024, 4, 29, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=46, title='April 2024 Midwest', start_date=datetime.datetime(2024, 4, 2, 12, 0), end_date=datetime.datetime(2024, 4, 3, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=47, title='April 2024 Great Plains + Midwest', start_date=datetime.datetime(2024, 4, 1, 12, 0), end_date=datetime.datetime(2024, 4, 2, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=48, title='March 2024 Midwest', start_date=datetime.datetime(2024, 3, 14, 12, 0), end_date=datetime.datetime(2024, 3, 15, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=49, title='February 2024 Midwest', start_date=datetime.datetime(2024, 2, 27, 12, 0), end_date=datetime.datetime(2024, 2, 28, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=50, title='January 2024 Southeast', start_date=datetime.datetime(2024, 1, 8, 12, 0), end_date=datetime.datetime(2024, 1, 10, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=51, title='December 2023 South', start_date=datetime.datetime(2023, 12, 9, 12, 0), end_date=datetime.datetime(2023, 12, 10, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=52, title='August 2023 East Coast', start_date=datetime.datetime(2023, 8, 7, 12, 0), end_date=datetime.datetime(2023, 8, 8, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=53, title='August 2023 Minnesota', start_date=datetime.datetime(2023, 8, 11, 12, 0), end_date=datetime.datetime(2023, 8, 12, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=54, title='July 2023 Midwest', start_date=datetime.datetime(2023, 7, 2, 12, 0), end_date=datetime.datetime(2023, 7, 3, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=55, title='July 2023 Midwest 2', start_date=datetime.datetime(2023, 7, 1, 12, 0), end_date=datetime.datetime(2023, 7, 2, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=56, title='June 2023 Midwest', start_date=datetime.datetime(2023, 6, 30, 12, 0), end_date=datetime.datetime(2023, 7, 1, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=57, title='June 2023 Front Range', start_date=datetime.datetime(2023, 6, 21, 12, 0), end_date=datetime.datetime(2023, 6, 22, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=58, title='June 2023 Texas', start_date=datetime.datetime(2023, 6, 21, 12, 0), end_date=datetime.datetime(2023, 6, 22, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=59, title='June 2023 Great Plains', start_date=datetime.datetime(2023, 6, 23, 12, 0), end_date=datetime.datetime(2023, 6, 24, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=60, title='June 2023 Iowa + Minnesota', start_date=datetime.datetime(2023, 6, 24, 12, 0), end_date=datetime.datetime(2023, 6, 25, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=61, title='June 2023 South + Midwest', start_date=datetime.datetime(2023, 6, 25, 12, 0), end_date=datetime.datetime(2023, 6, 26, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=62, title='June 2023 East Coast', start_date=datetime.datetime(2023, 6, 26, 12, 0), end_date=datetime.datetime(2023, 6, 27, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=63, title='June 2023 Midwest + Great Plains', start_date=datetime.datetime(2023, 6, 29, 12, 0), end_date=datetime.datetime(2023, 6, 30, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=64, title='June 2023 Southeast', start_date=datetime.datetime(2023, 6, 14, 12, 0), end_date=datetime.datetime(2023, 6, 15, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=65, title='June 2023 OK + TX + South', start_date=datetime.datetime(2023, 6, 15, 12, 0), end_date=datetime.datetime(2023, 6, 16, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=66, title='June 2023 South', start_date=datetime.datetime(2023, 6, 16, 12, 0), end_date=datetime.datetime(2023, 6, 17, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=67, title='June 2023 Mid-Atlantic', start_date=datetime.datetime(2023, 6, 16, 12, 0), end_date=datetime.datetime(2023, 6, 17, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=68, title='June 2023 Great Plains + South', start_date=datetime.datetime(2023, 6, 17, 12, 0), end_date=datetime.datetime(2023, 6, 18, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=69, title='May 2023 Great Plains', start_date=datetime.datetime(2023, 5, 10, 12, 0), end_date=datetime.datetime(2023, 5, 11, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=70, title='May 2023 Great Plains + South', start_date=datetime.datetime(2023, 5, 11, 12, 0), end_date=datetime.datetime(2023, 5, 12, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>]), CaseOperator(case=IndividualCase(case_id_number=71, title='May 2023 Nebraska', start_date=datetime.datetime(2023, 5, 12, 12, 0), end_date=datetime.datetime(2023, 5, 13, 12, 0), location=BoundingBoxRegion(latitude_min=24.0, latitude_max=54.0, longitude_min=245.0, longitude_max=295.0), event_type='severe_convection', data_vars=None, cross_listed=None), metrics=[<class '__main__.CSI'>, <class '__main__.LeadTimeDetection'>, <class '__main__.RegionalHitsMisses'>, <class '__main__.HitsMisses'>], observations=[<class '__main__.LSR'>])])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewb.event_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "severe = SevereConvection(case_metadata=case_yaml)\n",
    "\n",
    "# With the EventOperator class\n",
    "simple_event_operator = EventOperator(events=[severe])\n",
    "ewb = ExtremeWeatherBench(simple_event_operator, forecast_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x100bd85e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/taylor/.local/share/uv/python/cpython-3.13.1-macos-aarch64-none/lib/python3.13/_weakrefset.py\", line 39, in _remove\n",
      "    def _remove(item, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "for n in ewb.event_operator.pre_composed_case_operators:\n",
    "    test_output = ewb.process_observations(n)\n",
    "    ax = plot_practically_perfect_hindcast(test_output)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
