{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5215f81",
   "metadata": {},
   "source": [
    "# Code to generate all figures on freeze events used in the paper\n",
    "## note this is spread across multiple figures\n",
    "## TODO: Update the specific list once we are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdda01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5269e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup all the imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import urllib.request\n",
    "import matplotlib.font_manager\n",
    "flist = matplotlib.font_manager.get_font_names()\n",
    "from tempfile import NamedTemporaryFile\n",
    "import urllib\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "from extremeweatherbench import evaluate, utils, cases, defaults, inputs, metrics\n",
    "sns.set_theme(style='whitegrid')\n",
    "from shapely.geometry import Polygon\n",
    "import shapely\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# make the basepath - change this to your local path\n",
    "basepath = Path.home() / 'ExtremeWeatherBench' / ''\n",
    "basepath = str(basepath) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c00db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the templates to load in the data\n",
    "\n",
    "# Forecast Examples\n",
    "cira_freeze_forecast_FOURv2 = inputs.KerchunkForecast(\n",
    "    source=\"gs://extremeweatherbench/FOUR_v200_IFS.parq\",\n",
    "    variables=[\n",
    "        \"surface_air_temperature\",\n",
    "    ],\n",
    "    variable_mapping={\n",
    "        \"t2\": \"surface_air_temperature\",\n",
    "    },\n",
    "    storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}},\n",
    "    preprocess=defaults._preprocess_bb_cira_forecast_dataset,\n",
    "    name=\"FOURv2_IFS_CIRA\",\n",
    ")\n",
    "\n",
    "cira_freeze_forecast_GC = inputs.KerchunkForecast(\n",
    "    source=\"gs://extremeweatherbench/GRAP_v100_IFS.parq\",\n",
    "    variables=[\n",
    "        \"surface_air_temperature\",\n",
    "    ],\n",
    "    variable_mapping={\n",
    "        \"t2\": \"surface_air_temperature\",\n",
    "    },\n",
    "    storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}},\n",
    "    preprocess=defaults._preprocess_bb_cira_forecast_dataset,\n",
    "    name=\"GraphCast_IFS_CIRA\",\n",
    ")\n",
    "\n",
    "cira_freeze_forecast_PANG = inputs.KerchunkForecast(\n",
    "    source=\"gs://extremeweatherbench/PANG_v100_IFS.parq\",\n",
    "    variables=[\n",
    "        \"surface_air_temperature\",\n",
    "    ],\n",
    "    variable_mapping={\n",
    "        \"t2\": \"surface_air_temperature\",\n",
    "    },\n",
    "    storage_options={\"remote_protocol\": \"s3\", \"remote_options\": {\"anon\": True}},\n",
    "    preprocess=defaults._preprocess_bb_cira_forecast_dataset,\n",
    "    name=\"Pangu_IFS_CIRA\",\n",
    ")\n",
    "\n",
    "\n",
    "hres_forecast = inputs.ZarrForecast(\n",
    "    source=\"gs://weatherbench2/datasets/hres/2016-2022-0012-1440x721.zarr\",\n",
    "    variables=[\n",
    "        \"surface_air_temperature\",\n",
    "    ],\n",
    "    variable_mapping=inputs.HRES_metadata_variable_mapping,\n",
    "    storage_options={\"remote_options\": {\"anon\": True}},\n",
    "    name=\"HRES\",\n",
    ")\n",
    "\n",
    "\n",
    "FOURv2_GHCN_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.ghcn_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_FOURv2, \n",
    "    ),\n",
    "]\n",
    "\n",
    "FOURv2_ERA5_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.era5_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_FOURv2, \n",
    "    ),\n",
    "]\n",
    "\n",
    "GC_GHCN_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.ghcn_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_GC, \n",
    "    ),\n",
    "]\n",
    "\n",
    "GC_ERA5_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.era5_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_GC, \n",
    "    ),\n",
    "]\n",
    "\n",
    "PANG_GHCN_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.ghcn_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_PANG, \n",
    "    ),\n",
    "]\n",
    "\n",
    "PANG_ERA5_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.era5_heatwave_target,\n",
    "        forecast=cira_freeze_forecast_PANG, \n",
    "    ),\n",
    "]\n",
    "\n",
    "HRES_GHCN_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.ghcn_heatwave_target,\n",
    "        forecast=hres_forecast,\n",
    "    ),\n",
    "]\n",
    "\n",
    "HRES_ERA5_EVALUATION_OBJECTS = [\n",
    "    inputs.EvaluationObject(\n",
    "        event_type=\"freeze\",\n",
    "        metric_list=[\n",
    "            metrics.MinimumMAE,\n",
    "            metrics.RMSE,\n",
    "            metrics.OnsetME,\n",
    "            metrics.DurationME,\n",
    "        ],\n",
    "        target=defaults.era5_heatwave_target,\n",
    "        forecast=hres_forecast,\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5348a418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function is deprecated and will be removed in a future release. Please use cases.load_ewb_events_yaml_into_case_collection instead.\n",
      "This function is deprecated and will be removed in a future release. Please use cases.read_incoming_yaml instead.\n"
     ]
    }
   ],
   "source": [
    "# load in all of the events in the yaml file\n",
    "case_dict = utils.load_events_yaml()\n",
    "freeze_test = {\"cases\": case_dict[\"cases\"]}\n",
    "\n",
    "# turn the dictionary into a list of case objects ()\n",
    "ewb_cases = cases.load_individual_cases(case_dict)\n",
    "\n",
    "# create the evaluation objects for each model\n",
    "ewb_fourv2_ghcn = evaluate.ExtremeWeatherBench(freeze_test, FOURv2_GHCN_EVALUATION_OBJECTS)\n",
    "ewb_fourv2_era5 = evaluate.ExtremeWeatherBench(freeze_test, FOURv2_ERA5_EVALUATION_OBJECTS)\n",
    "\n",
    "ewb_gc_ghcn = evaluate.ExtremeWeatherBench(freeze_test, GC_GHCN_EVALUATION_OBJECTS)\n",
    "ewb_gc_era5 = evaluate.ExtremeWeatherBench(freeze_test, GC_ERA5_EVALUATION_OBJECTS)\n",
    "\n",
    "ewb_pang_ghcn = evaluate.ExtremeWeatherBench(freeze_test, PANG_GHCN_EVALUATION_OBJECTS)\n",
    "ewb_pang_era5 = evaluate.ExtremeWeatherBench(freeze_test, PANG_ERA5_EVALUATION_OBJECTS)\n",
    "\n",
    "ewb_hres_ghcn = evaluate.ExtremeWeatherBench(freeze_test, HRES_GHCN_EVALUATION_OBJECTS)\n",
    "ewb_hres_era5 = evaluate.ExtremeWeatherBench(freeze_test, HRES_ERA5_EVALUATION_OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f6a43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7385143791444d99048c92a8b2e9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n",
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01316aa8bad944028c3a4da79d182f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n",
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b16783299e4566a5e0c7a481394648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n",
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e0ae21ff574245a0be07d9afb12a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n",
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc590a0ac18e445682fcc14b7a1ca0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n",
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43298e51772b4b47856418056c56ee20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 91 has no data for case time range 2021-03-04 18:00:00 to 2021-03-10 18:00:00.\n",
      "Forecast dataset for case 30 has no data for case time range 2021-02-10 12:00:00 to 2021-02-22 00:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e942c8ae58dd455485a60c12fcb794d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 33 has no data for case time range 2023-12-15 06:00:00 to 2023-12-26 18:00:00.\n",
      "Forecast dataset for case 89 has no data for case time range 2024-01-11 12:00:00 to 2024-01-20 00:00:00.\n",
      "Forecast dataset for case 32 has no data for case time range 2023-12-02 06:00:00 to 2023-12-08 06:00:00.\n",
      "Forecast dataset for case 94 has no data for case time range 2024-04-16 12:00:00 to 2024-04-27 12:00:00.\n",
      "Forecast dataset for case 96 has no data for case time range 2024-04-02 00:00:00 to 2024-04-08 00:00:00.\n",
      "Forecast dataset for case 95 has no data for case time range 2024-01-20 00:00:00 to 2024-02-04 18:00:00.\n",
      "Forecast dataset for case 92 has no data for case time range 2024-01-01 06:00:00 to 2024-01-09 12:00:00.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f61ea1f6c224f849b66e19b1f7d1411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecast dataset for case 32 has no data for case time range 2023-12-02 06:00:00 to 2023-12-08 06:00:00.\n",
      "Forecast dataset for case 89 has no data for case time range 2024-01-11 12:00:00 to 2024-01-20 00:00:00.\n",
      "Forecast dataset for case 33 has no data for case time range 2023-12-15 06:00:00 to 2023-12-26 18:00:00.\n",
      "Forecast dataset for case 96 has no data for case time range 2024-04-02 00:00:00 to 2024-04-08 00:00:00.\n",
      "Forecast dataset for case 92 has no data for case time range 2024-01-01 06:00:00 to 2024-01-09 12:00:00.\n",
      "Forecast dataset for case 94 has no data for case time range 2024-04-16 12:00:00 to 2024-04-27 12:00:00.\n",
      "Forecast dataset for case 95 has no data for case time range 2024-01-20 00:00:00 to 2024-02-04 18:00:00.\n"
     ]
    }
   ],
   "source": [
    "# load in the results for all heat waves in parallel\n",
    "# this will take awhile to run if you do them all in one code box so I commented most of them out here and copied them below\n",
    "n_threads_per_process = 4\n",
    "n_processes = max(1, multiprocessing.cpu_count() // n_threads_per_process)\n",
    "\n",
    "fourv2_ghcn_results = ewb_fourv2_ghcn.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "fourv2_era5_results = ewb_fourv2_era5.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "\n",
    "gc_ghcn_results = ewb_gc_ghcn.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "gc_era5_results = ewb_gc_era5.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "\n",
    "pang_ghcn_results = ewb_pang_ghcn.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "pang_era5_results = ewb_pang_era5.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "\n",
    "hres_ghcn_results = ewb_hres_ghcn.run(parallel=True, n_jobs=n_processes, pre_compute=True)\n",
    "hres_era5_results = ewb_hres_era5.run(parallel=True, n_jobs=n_processes, pre_compute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9c47e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results so I don't have to keep re-running\n",
    "fourv2_ghcn_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_fourv2_ghcn_freeze_results.pkl')\n",
    "fourv2_era5_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_fourv2_era5_freeze_results.pkl')\n",
    "\n",
    "pang_ghcn_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_pang_ghcn_freeze_results.pkl')\n",
    "pang_era5_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_pang_era5_freeze_results.pkl')\n",
    "\n",
    "hres_ghcn_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_hres_ghcn_freeze_results.pkl')\n",
    "hres_era5_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_hres_era5_freeze_results.pkl')\n",
    "\n",
    "gc_era5_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_gc_era5_freeze_results.pkl')\n",
    "gc_ghcn_results.to_pickle(basepath + 'docs/notebooks/figs/figure2_part2_gc_ghcn_freeze_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results back in\n",
    "fourv2_ghcn_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_fourv2_ghcn_freeze_results.pkl')\n",
    "fourv2_era5_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_fourv2_era5_freeze_results.pkl')\n",
    "\n",
    "pang_ghcn_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_pang_ghcn_freeze_results.pkl')\n",
    "pang_era5_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_pang_era5_freeze_results.pkl')\n",
    "\n",
    "hres_ghcn_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_hres_ghcn_freeze_results.pkl')\n",
    "hres_era5_results = pd.read_pickle(basepath + 'docs/notebooks/figs/figure2_part2_hres_era5_freeze_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb755098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique list of metrics\n",
    "unique_metrics = fourv2_ghcn_results['metric'].unique()\n",
    "print(unique_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c53677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the results by metric and lead time and take the mean across cases\n",
    "fourv2_ghcn_group = fourv2_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "fourv2_ghcn_group = fourv2_ghcn_group.reset_index()\n",
    "\n",
    "fourv2_era5_group = fourv2_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "fourv2_era5_group = fourv2_era5_group.reset_index()\n",
    "\n",
    "# gc_ghcn_group = gc_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "# gc_ghcn_group = gc_ghcn_group.reset_index()\n",
    "\n",
    "# gc_era5_group = gc_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "# gc_era5_group = gc_era5_group.reset_index()\n",
    "\n",
    "pang_ghcn_group = pang_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "pang_ghcn_group = pang_ghcn_group.reset_index()\n",
    "\n",
    "pang_era5_group = pang_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "pang_era5_group = pang_era5_group.reset_index()\n",
    "\n",
    "hres_ghcn_group = hres_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "hres_ghcn_group = hres_ghcn_group.reset_index()\n",
    "\n",
    "hres_era5_group = hres_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean()\n",
    "hres_era5_group = hres_era5_group.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b88640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_by_metric(metric='rmse', filename=None, title='RMSE for All Heat Waves', forecast_hour=None):\n",
    "    # make the pivot table so we can plot by lead time\n",
    "    fourv2_ghcn_pivot = fourv2_ghcn_group[fourv2_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "    fourv2_era_pivot = fourv2_era5_group[fourv2_era5_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    pang_ghcn_pivot = pang_ghcn_group[pang_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "    pang_era5_pivot = pang_era5_group[pang_era5_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    hres_ghcn_pivot = hres_ghcn_group[hres_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "    hres_era5_pivot = hres_era5_group[hres_era5_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    if (forecast_hour == \"zeroz\"):\n",
    "        # extract the 0z runs\n",
    "        time_diff = hres_era5_pivot.columns.seconds % 86400 == 0\n",
    "        zeroz = [idx for idx, n in enumerate(time_diff) if n]\n",
    "        \n",
    "        # subset down to only the 0z runs\n",
    "        fourv2_ghcn_pivot = fourv2_ghcn_pivot.iloc[:, zeroz]\n",
    "        fourv2_era_pivot = fourv2_era_pivot.iloc[:, zeroz]\n",
    "\n",
    "        pang_ghcn_pivot = pang_ghcn_pivot.iloc[:, zeroz]\n",
    "        pang_era5_pivot = pang_era5_pivot.iloc[:, zeroz]    \n",
    "\n",
    "        hres_ghcn_pivot = hres_ghcn_pivot.iloc[:, zeroz]\n",
    "        hres_era5_pivot = hres_era5_pivot.iloc[:, zeroz]\n",
    "    elif (forecast_hour == \"twelvez\"):\n",
    "        # extract the 12z runs\n",
    "        time_diff = hres_era5_pivot.columns.seconds % 86400 == 43200\n",
    "        twelvez = [idx for idx, n in enumerate(time_diff) if n]\n",
    "        \n",
    "        # subset down to only the 12z runs\n",
    "        fourv2_ghcn_pivot = fourv2_ghcn_pivot.iloc[:, twelvez]\n",
    "        fourv2_era_pivot = fourv2_era_pivot.iloc[:, twelvez]\n",
    "\n",
    "        pang_ghcn_pivot = pang_ghcn_pivot.iloc[:, twelvez]\n",
    "        pang_era5_pivot = pang_era5_pivot.iloc[:, twelvez]    \n",
    "\n",
    "        hres_ghcn_pivot = hres_ghcn_pivot.iloc[:, twelvez]\n",
    "        hres_era5_pivot = hres_era5_pivot.iloc[:, twelvez]\n",
    "        \n",
    "\n",
    "    # make the plots\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    sns_palette = sns.color_palette(\"tab10\")\n",
    "    fig, ax = plt.subplots(figsize=(16,4))\n",
    "    fourv2_ghcn_values = fourv2_ghcn_pivot.loc[metric].values\n",
    "    fourv2_era5_values = fourv2_era_pivot.loc[metric].values\n",
    "    pang_ghcn_values = pang_ghcn_pivot.loc[metric].values\n",
    "    pang_era5_values = pang_era5_pivot.loc[metric].values\n",
    "    hres_ghcn_values = hres_ghcn_pivot.loc[metric].values\n",
    "    hres_era5_values = hres_era5_pivot.loc[metric].values\n",
    "\n",
    "    plt.plot(np.flip(fourv2_ghcn_values), color=sns_palette[0], label='FourCastNet V2 GHCN', linewidth=2)\n",
    "    plt.plot(np.flip(fourv2_era5_values), color=sns_palette[0], linestyle='--', label='FourCastNet V2 ERA5', linewidth=2)\n",
    "\n",
    "    plt.plot(np.flip(pang_ghcn_values), color=sns_palette[1], label='Pangu Weather GHCN', linewidth=2)\n",
    "    plt.plot(np.flip(pang_era5_values), color=sns_palette[1], linestyle='--', label='Pangu Weather ERA5', linewidth=2)  \n",
    "\n",
    "    plt.plot(np.flip(hres_ghcn_values), color=sns_palette[2], label='HRES GHCN', linewidth=2)\n",
    "    plt.plot(np.flip(hres_era5_values), color=sns_palette[2], linestyle='--', label='HRES ERA5', linewidth=2)\n",
    "\n",
    "    # make the xticklabels more readable and show every other one\n",
    "    # print(np.arange(0, len(merged_pivot.columns), 2))\n",
    "    # print(merged_pivot.columns[::2])\n",
    "    ax.set_xticks(rotation=90, labels=np.flip(fourv2_ghcn_pivot.columns), ticks=np.arange(0, len(fourv2_ghcn_pivot.columns), 1))\n",
    "    #ax.set_xticks(ticks=np.arange(0, len(merged_pivot.columns), 2))\n",
    "\n",
    "    ax.set_ylabel('Celsius')\n",
    "    ax.set_xlabel('Initialization Time')\n",
    "    plt.title(title)\n",
    "    #ax.grid(True, which='both', axis='both', color='lightgrey', linestyle='--', linewidth=0.5)\n",
    "    plt.legend(loc='best', fontsize=12)\n",
    "\n",
    "    if (filename is not None):\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099d6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_by_metric(metric='minimum_mae', filename=basepath + 'docs/notebooks/figs/figure2_part2_maximum_mae_freeze_0z.png', \n",
    "                       title='Minimum Temp MAE at 0Z for All Freezes', forecast_hour=\"zeroz\")\n",
    "plot_results_by_metric(metric='rmse', filename=basepath + 'docs/notebooks/figs/figure2_part2_rmse_freeze.png', \n",
    "                       title='RMSE at 0Z for All Freezes', forecast_hour=\"zeroz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792aade",
   "metadata": {},
   "source": [
    "# subset the data into regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to convert a bounding box tuple to a shapely Polygon\n",
    "def get_polygon_from_bounding_box(bounding_box):\n",
    "    \"\"\"Convert a bounding box tuple to a shapely Polygon.\"\"\"\n",
    "    if bounding_box is None:\n",
    "        return None\n",
    "    left_lon, right_lon, bot_lat, top_lat = bounding_box\n",
    "    return Polygon(\n",
    "        [\n",
    "            (left_lon, bot_lat),\n",
    "            (right_lon, bot_lat),\n",
    "            (right_lon, top_lat),\n",
    "            (left_lon, top_lat),\n",
    "            (left_lon, bot_lat),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# North America\n",
    "na_bounding_box = [-172, -45, 7, 85]\n",
    "na_bounding_box_polygon = get_polygon_from_bounding_box(na_bounding_box)\n",
    "\n",
    "# Europe bounding box\n",
    "eu_bounding_box = [50, -15, 15, 75]\n",
    "eu_bounding_box_polygon = get_polygon_from_bounding_box(eu_bounding_box)\n",
    "\n",
    "# australia bounding box\n",
    "au_bounding_box = [110, 180, -50, -10]\n",
    "au_bounding_box_polygon = get_polygon_from_bounding_box(au_bounding_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxes on a global map so we can see where they are\n",
    "\n",
    "# helper function to plot a polygon on a cartopy axis\n",
    "def plot_polygon(polygon, ax, color='yellow', alpha=0.5, my_zorder=1):\n",
    "    \"\"\"Plot a shapely Polygon on a Cartopy axis.\"\"\"\n",
    "    if polygon is None:\n",
    "        return\n",
    "    patch = patches.Polygon(\n",
    "        polygon.exterior.coords,\n",
    "        closed=True,\n",
    "        facecolor=color,\n",
    "        edgecolor=color,\n",
    "        alpha=alpha,\n",
    "        linewidth=2,\n",
    "        zorder=my_zorder,\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "# helper function to plot a polygon on a cartopy axis\n",
    "def plot_polygon_outline(polygon, ax, color='yellow', alpha=0.5, my_zorder=1):\n",
    "    \"\"\"Plot a shapely Polygon on a Cartopy axis.\"\"\"\n",
    "    if polygon is None:\n",
    "        return\n",
    "    patch = patches.Polygon(\n",
    "        polygon.exterior.coords,\n",
    "        closed=True,\n",
    "        facecolor='none',\n",
    "        edgecolor=color,\n",
    "        alpha=alpha,\n",
    "        linewidth=2,\n",
    "        zorder=my_zorder,\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "\n",
    "\n",
    "# main plotting function for plotting all cases\n",
    "def plot_boxes(box_list, box_names, title, filename=None):\n",
    "    # plot all cases on one giant world map\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.set_global()\n",
    "        \n",
    "    # Add coastlines and gridlines\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor='black', facecolor='white')\n",
    "    ax.add_feature(cfeature.RIVERS, edgecolor='black')\n",
    "\n",
    "    # Add gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='black', alpha=1, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xformatter = LongitudeFormatter()\n",
    "    gl.yformatter = LatitudeFormatter()\n",
    "\n",
    "    # Define colors for each event type\n",
    "    # use seaborn color palette for colorblind friendly colors\n",
    "    sns_palette = sns.color_palette(\"tab10\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # Plot boxes for each case\n",
    "    for box in box_list:\n",
    "        plot_polygon_outline(box, ax, color='blue', alpha=1)\n",
    "\n",
    "    plt.legend(loc='lower left', fontsize=12)\n",
    "    ax.set_title(title, loc='left', fontsize=20)\n",
    "    \n",
    "    # save if there is a filename specified (otherwise the user just wants to see the plot)\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, transparent=False, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baeecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxes(\n",
    "    box_list=[na_bounding_box_polygon, eu_bounding_box_polygon],\n",
    "    box_names=['North America', 'Europe', 'Australia'],\n",
    "    title='Regions Used for Regional Analysis',\n",
    "    filename=basepath + 'docs/notebooks/figure3_part1_regions.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main plotting function for plotting all cases\n",
    "def plot_all_cases(ewb_cases, event_type=None, filename=None, bounding_box=None, fill_boxes=False, event_id=None):\n",
    "    \"\"\"A function to plot all cases\n",
    "    Args:\n",
    "        ewb_cases (list): A list of cases to plot.\n",
    "        event_type (str): The type of event to plot. If None, all events will be plotted).\n",
    "        filename (str): The name of the file to save the plot. If None, the plot will not be saved.\n",
    "        bounding_box (tuple): A tuple of the form (min_lon, min_lat, max_lon, max_lat) to set the bounding box for the plot. If None, the full world map will be plotted.\n",
    "    \"\"\"\n",
    "    # plot all cases on one giant world map\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "    # plot the full map or a subset if bounding_box is specified\n",
    "    if (bounding_box is None):\n",
    "        ax.set_global()\n",
    "    else:\n",
    "        ax.set_extent(bounding_box, crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # save the bounding box polygon to subset the counts later\n",
    "    if (bounding_box is not None):\n",
    "        bounding_box_polygon = get_polygon_from_bounding_box(bounding_box)\n",
    "        #plot_polygon(bounding_box_polygon, ax, color='yellow', alpha=0.5)\n",
    "        \n",
    "    # Add coastlines and gridlines\n",
    "    ax.coastlines()\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black')\n",
    "    ax.add_feature(cfeature.LAKES, edgecolor='black', facecolor='white')\n",
    "    ax.add_feature(cfeature.RIVERS, edgecolor='black')\n",
    "\n",
    "    # Add gridlines\n",
    "    gl = ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xformatter = LongitudeFormatter()\n",
    "    gl.yformatter = LatitudeFormatter()\n",
    "\n",
    "    # Define colors for each event type\n",
    "    # use seaborn color palette for colorblind friendly colors\n",
    "    sns_palette = sns.color_palette(\"tab10\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    # event_colors = {\n",
    "    #     'heat_wave': 'firebrick',\n",
    "    #     'tropical_cyclone': 'darkorange',\n",
    "    #     'severe_convection': 'orchid',\n",
    "    #     'atmospheric_river': 'mediumseagreen',\n",
    "    #     'freeze': 'royalblue',   \n",
    "    # }\n",
    "    event_colors = {\n",
    "            'freeze': sns_palette[0],  \n",
    "            'heat_wave': sns_palette[3],\n",
    "            'tropical_cyclone': sns_palette[1],\n",
    "            'severe_convection': sns_palette[5],\n",
    "            'atmospheric_river': sns_palette[7],\n",
    "        }\n",
    "\n",
    "    # Initialize counts for each event type\n",
    "    counts_by_type = dict({'freeze': 0, 'heat_wave': 0, 'severe_convection': 0, 'atmospheric_river': 0, 'tropical_cyclone': 0})\n",
    "    zorders = {'freeze': 10, 'heat_wave': 9, 'atmospheric_river': 2, 'tropical_cyclone': 1, 'severe_convection': 0}\n",
    "    alphas = {'freeze': 0.2, 'heat_wave': 0.2, 'atmospheric_river': 0.2, 'tropical_cyclone': 0.2, 'severe_convection': 0.05}\n",
    "\n",
    "    # Plot boxes for each case\n",
    "    for indiv_case in ewb_cases.cases:\n",
    "        # Get color based on event type\n",
    "        indiv_event_type = indiv_case.event_type\n",
    "        color = event_colors.get(indiv_event_type, 'gray')  # Default to gray if event type not found\n",
    "\n",
    "        # check if the case is inside the bounding box\n",
    "        if bounding_box is not None:\n",
    "            if (not shapely.intersects(indiv_case.location.geopandas.geometry[0], bounding_box_polygon)):\n",
    "                #print(f\"Skipping case {indiv_case.case_id_number} as it is outside the bounding box.\")\n",
    "                continue\n",
    "        \n",
    "        # Plot the case geopandas info\n",
    "        if (event_type is None or indiv_event_type == event_type and event_id is None) or (event_id is not None and indiv_case.case_id_number == event_id):\n",
    "            if (fill_boxes):\n",
    "                # to handle wrapping around the prime meridian, we can't use geopandas plot (and besides it is slow)\n",
    "                # instead we have multi-polygon patches if it wraps around and we need to plot each polygon separately\n",
    "                if isinstance(indiv_case.location.geopandas.geometry.iloc[0], shapely.geometry.MultiPolygon):\n",
    "                    for poly in indiv_case.location.geopandas.geometry.iloc[0].geoms:\n",
    "                        plot_polygon(poly, ax, color=color, alpha=alphas[indiv_event_type], my_zorder=zorders[indiv_event_type])\n",
    "                else:\n",
    "                    plot_polygon(indiv_case.location.geopandas.geometry.iloc[0], ax, color=color, \n",
    "                                alpha=alphas[indiv_event_type], my_zorder=zorders[indiv_event_type])\n",
    "            else:\n",
    "                # to handle wrapping around the prime meridian, we can't use geopandas plot (and besides it is slow)\n",
    "                # instead we have multi-polygon patches if it wraps around and we need to plot each polygon separately\n",
    "                if isinstance(indiv_case.location.geopandas.geometry.iloc[0], shapely.geometry.MultiPolygon):\n",
    "                    for poly in indiv_case.location.geopandas.geometry.iloc[0].geoms:\n",
    "                        plot_polygon_outline(poly, ax, color=color, alpha=1, my_zorder=zorders[indiv_event_type])\n",
    "                else:\n",
    "                    plot_polygon_outline(indiv_case.location.geopandas.geometry.iloc[0], ax, color=color, \n",
    "                                alpha=1, my_zorder=zorders[indiv_event_type])\n",
    "\n",
    "            # count the events by type\n",
    "            counts_by_type[indiv_event_type] += 1\n",
    "\n",
    "        \n",
    "    # Create a custom legend for event types\n",
    "    if (event_type is not None):\n",
    "        # if we are only plotting one event type, only show that in the legend\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=event_colors[event_type], alpha=0.9, label=f'{event_type.replace(\"_\", \" \").title()} (n = %d)' % counts_by_type[event_type]),\n",
    "        ]\n",
    "    else:\n",
    "        # otherwise show all event types in the legend\n",
    "        legend_elements = [\n",
    "            Patch(facecolor=event_colors['heat_wave'], alpha=0.9, label='Heat Wave (n = %d)' % counts_by_type['heat_wave']),\n",
    "            Patch(facecolor=event_colors['freeze'], alpha=0.9, label='Freeze (n = %d)' % counts_by_type['freeze']),\n",
    "            Patch(facecolor=event_colors['severe_convection'], alpha=0.9, label='Convection (n = %d)' % counts_by_type['severe_convection']),\n",
    "            Patch(facecolor=event_colors['atmospheric_river'], alpha=0.9, label='Atmospheric River (n = %d)' % counts_by_type['atmospheric_river']),\n",
    "            Patch(facecolor=event_colors['tropical_cyclone'], alpha=0.9, label='Tropical Cyclone (n = %d)' % counts_by_type['tropical_cyclone']),\n",
    "        ]\n",
    "\n",
    "    # Create a larger legend by specifying a larger font size in the prop dictionary\n",
    "    ax.legend(handles=legend_elements, loc='lower left', framealpha=1, frameon=True, borderpad=0.5, handletextpad=0.8, handlelength=2.5)\n",
    "    if (event_type is None):\n",
    "        title = 'ExtremeWeatherBench Cases (n = %d)' % sum(counts_by_type.values())\n",
    "    else:\n",
    "        title = f'ExtremeWeatherBench Cases: {event_type.replace(\"_\", \" \").title()} (n = %d)' % counts_by_type[event_type]\n",
    "\n",
    "    if (event_id is not None):\n",
    "        title = f'ExtremeWeatherBench Case ID: {event_id}'\n",
    "    \n",
    "    ax.set_title(title, loc='left', fontsize=20)\n",
    "    \n",
    "    # save if there is a filename specified (otherwise the user just wants to see the plot)\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, transparent=False, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb51921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cases for the regions we are analyzing\n",
    "plot_all_cases(ewb_cases, event_type='freeze', bounding_box=na_bounding_box, \n",
    "               filename=basepath + 'docs/notebooks/figs/extreme_weather_freeze_cases_NA.png', fill_boxes=True)\n",
    "\n",
    "plot_all_cases(ewb_cases, event_type='freeze', bounding_box=eu_bounding_box, \n",
    "               filename=basepath + 'docs/notebooks/figs/extreme_weather_freeze_cases_EU.png', fill_boxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d96904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the list of cases by region\n",
    "na_cases = list()\n",
    "eu_cases = list()\n",
    "\n",
    "for case in ewb_fourv2_era5.case_operators:\n",
    "    #print(heat_case.case_metadata)\n",
    "\n",
    "    my_case = case.case_metadata\n",
    "\n",
    "    # collect the North America, Europe, and Australia cases\n",
    "    if (shapely.intersects(my_case.location.geopandas.geometry[0], na_bounding_box_polygon)):\n",
    "        na_cases.append(my_case.case_id_number)\n",
    "    elif (shapely.intersects(my_case.location.geopandas.geometry[0], eu_bounding_box_polygon)):\n",
    "        eu_cases.append(my_case.case_id_number)\n",
    "    \n",
    "\n",
    "print(f'North America Cases: {na_cases}')\n",
    "print(f'Europe Cases: {eu_cases}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caff61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all the subsets\n",
    "na_fourv2_era5_results = fourv2_era5_results[fourv2_era5_results['case_id_number'].isin(na_cases)]\n",
    "eu_fourv2_era5_results = fourv2_era5_results[fourv2_era5_results['case_id_number'].isin(eu_cases)]\n",
    "\n",
    "na_fourv2_ghcn_results = fourv2_ghcn_results[fourv2_ghcn_results['case_id_number'].isin(na_cases)]\n",
    "eu_fourv2_ghcn_results = fourv2_ghcn_results[fourv2_ghcn_results['case_id_number'].isin(eu_cases)]\n",
    "\n",
    "na_pang_era5_results = pang_era5_results[pang_era5_results['case_id_number'].isin(na_cases)]\n",
    "eu_pang_era5_results = pang_era5_results[pang_era5_results['case_id_number'].isin(eu_cases)]\n",
    "\n",
    "na_pang_ghcn_results = pang_ghcn_results[pang_ghcn_results['case_id_number'].isin(na_cases)]\n",
    "eu_pang_ghcn_results = pang_ghcn_results[pang_ghcn_results['case_id_number'].isin(eu_cases)]\n",
    "\n",
    "na_hres_era5_results = hres_era5_results[hres_era5_results['case_id_number'].isin(na_cases)]\n",
    "eu_hres_era5_results = hres_era5_results[hres_era5_results['case_id_number'].isin(eu_cases)]\n",
    "\n",
    "na_hres_ghcn_results = hres_ghcn_results[hres_ghcn_results['case_id_number'].isin(na_cases)]\n",
    "eu_hres_ghcn_results = hres_ghcn_results[hres_ghcn_results['case_id_number'].isin(eu_cases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the groupby for each subset\n",
    "# fourcastnet v2\n",
    "na_fourv2_ghcn_group = na_fourv2_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "na_fourv2_era5_group = na_fourv2_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "\n",
    "eu_fourv2_ghcn_group = eu_fourv2_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "eu_fourv2_ghcn_group = eu_fourv2_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "\n",
    "# pangu\n",
    "na_pang_ghcn_group = na_pang_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "na_pang_era5_group = na_pang_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "\n",
    "eu_pang_ghcn_group = eu_pang_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "eh_pang_era5_group = eu_pang_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "\n",
    "# hres\n",
    "na_hres_ghcn_group = na_hres_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "na_hres_era5_group = na_hres_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "\n",
    "eu_hres_ghcn_group = eu_hres_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "eu_hres_era5_group = eu_hres_era5_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abebc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_by_metric(metric='rmse', filename=None, title='RMSE for All Heat Waves', \n",
    "                           fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results,\n",
    "                           global_fourv2_ghcn=fourv2_ghcn_results, global_pang_ghcn=pang_ghcn_results, global_hres_ghcn=hres_ghcn_results,\n",
    "                           forecast_hour=None):\n",
    "    # make the pivot table so we can plot by lead time\n",
    "    fourv2_ghcn_group = fourv2_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    fourv2_ghcn_pivot = fourv2_ghcn_group[fourv2_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    pang_ghcn_group = pang_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    pang_ghcn_pivot = pang_ghcn_group[pang_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    hres_ghcn_group = hres_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    hres_ghcn_pivot = hres_ghcn_group[hres_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    # grab the global results for reference lines\n",
    "    global_fourv2_ghcn_group = global_fourv2_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_fourv2_ghcn_pivot = global_fourv2_ghcn_group[global_fourv2_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    global_pang_ghcn_group = global_pang_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_pang_ghcn_pivot = global_pang_ghcn_group[global_pang_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    global_hres_ghcn_group = global_hres_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_hres_ghcn_pivot = global_hres_ghcn_group[global_hres_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    if (forecast_hour == \"zeroz\"):\n",
    "        # extract the 0z runs\n",
    "        time_diff = fourv2_ghcn_pivot.columns.seconds % 86400 == 0\n",
    "        my_times = [idx for idx, n in enumerate(time_diff) if n]\n",
    "\n",
    "    elif (forecast_hour == \"twelvez\"):\n",
    "        # extract the 12z runs\n",
    "        time_diff = fourv2_ghcn_pivot.columns.seconds % 86400 == 43200\n",
    "        my_times = [idx for idx, n in enumerate(time_diff) if n]\n",
    "\n",
    "    if (forecast_hour is not None):\n",
    "        fourv2_ghcn_pivot = fourv2_ghcn_pivot.iloc[:, my_times]\n",
    "        pang_ghcn_pivot = pang_ghcn_pivot.iloc[:, my_times]\n",
    "        hres_ghcn_pivot = hres_ghcn_pivot.iloc[:, my_times]\n",
    "\n",
    "        global_fourv2_ghcn_pivot = global_fourv2_ghcn_pivot.iloc[:, my_times]\n",
    "        global_pang_ghcn_pivot = global_pang_ghcn_pivot.iloc[:, my_times]\n",
    "        global_hres_ghcn_pivot = global_hres_ghcn_pivot.iloc[:, my_times]  \n",
    "\n",
    "\n",
    "    # make the plots\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(15,4))\n",
    "    fourv2_ghcn_values = fourv2_ghcn_pivot.loc[metric].values\n",
    "    pang_ghcn_values = pang_ghcn_pivot.loc[metric].values\n",
    "    hres_ghcn_values = hres_ghcn_pivot.loc[metric].values\n",
    "\n",
    "    global_fourv2_ghcn_values = global_fourv2_ghcn_pivot.loc[metric].values\n",
    "    global_pang_ghcn_values = global_pang_ghcn_pivot.loc[metric].values\n",
    "    global_hres_ghcn_values = global_hres_ghcn_pivot.loc[metric].values\n",
    "\n",
    "    plt.plot(np.flip(fourv2_ghcn_values), 'r', label='FourCastNet V2 GHCN')\n",
    "    plt.plot(np.flip(global_fourv2_ghcn_values), 'r--', label='Global FourCastNet V2 GHCN')\n",
    "\n",
    "    plt.plot(np.flip(pang_ghcn_values), 'g', label='Pangu Weather GHCN')\n",
    "    plt.plot(np.flip(global_pang_ghcn_values), 'g--', label='Global Pangu Weather GHCN')\n",
    "\n",
    "    plt.plot(np.flip(hres_ghcn_values), 'm', label='HRES GHCN')\n",
    "    plt.plot(np.flip(global_hres_ghcn_values), 'm--', label='Global HRES GHCN')\n",
    "\n",
    "    # make the xticklabels more readable and show every other one\n",
    "    # print(np.arange(0, len(merged_pivot.columns), 2))\n",
    "    # print(merged_pivot.columns[::2])\n",
    "    ax.set_xticks(rotation=90, labels=np.flip(fourv2_ghcn_pivot.columns), ticks=np.arange(0, len(fourv2_ghcn_pivot.columns)))\n",
    "    #ax.set_xticks(ticks=np.arange(0, len(merged_pivot.columns), 2))\n",
    "\n",
    "    ax.set_ylabel('Celsius')\n",
    "    ax.set_xlabel('Initialization Time')\n",
    "    plt.title(title)\n",
    "    #ax.grid(True, which='both', axis='both', color='lightgrey', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    if (filename is not None):\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_by_metric(metric='rmse', filename=basepath + 'docs/notebooks/figs/figure2_part2_maximum_mae_na.png', title='RMSE for 0Z North American Freezes', \n",
    "                       fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results, \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       forecast_hour='zeroz')\n",
    "\n",
    "plot_results_by_metric(metric='rmse', filename=basepath + 'docs/notebooks/figs/figure2_part2_maximum_mae_eu.png', title='RMSE for 0Z European Freezes', \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       fourv2_ghcn=eu_fourv2_ghcn_results, pang_ghcn=eu_pang_ghcn_results, hres_ghcn=eu_hres_ghcn_results, forecast_hour='zeroz')\n",
    "\n",
    "plot_results_by_metric(metric='minimum_mae', filename=basepath + 'docs/notebooks/figs/figure2_part2_maximum_mae_na.png', \n",
    "                       title='Minimum Temp MAE at 0Z for 0Z North American Freezes', \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results, forecast_hour='zeroz')\n",
    "\n",
    "plot_results_by_metric(metric='minimum_mae', filename=basepath + 'docs/notebooks/figs/figure2_part2_maximum_mae_eu.png', \n",
    "                       title='Minimum Temp MAE at 0Z for 0Z European Freezes', \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       fourv2_ghcn=eu_fourv2_ghcn_results, pang_ghcn=eu_pang_ghcn_results, hres_ghcn=eu_hres_ghcn_results, forecast_hour='zeroz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782dbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look through the north america cases to decide which one to look in depth\n",
    "for freeze_case in ewb_cases.cases:\n",
    "    \n",
    "    if (freeze_case.case_id_number in na_cases):\n",
    "        print(freeze_case)  \n",
    "\n",
    "        #plot_all_cases(ewb_cases, event_type='freeze', bounding_box=na_bounding_box, fill_boxes=True, event_id=freeze_case.case_id_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to dive into case 31 in more detail\n",
    "for case in ewb_cases.cases:\n",
    "    if (case.case_id_number == 31):\n",
    "        my_case = case\n",
    "        print(my_case)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_case_results_by_metric(metric='rmse', filename=None, title='RMSE for All Heat Waves', \n",
    "                           fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results,\n",
    "                           global_fourv2_ghcn=fourv2_ghcn_results, global_pang_ghcn=pang_ghcn_results, global_hres_ghcn=hres_ghcn_results,\n",
    "                           forecast_hour=None, event_id=None):\n",
    "    \n",
    "    # subset the results to just this metric and event id\n",
    "    fourv2_ghcn = fourv2_ghcn[fourv2_ghcn['case_id_number'] == my_case.case_id_number]\n",
    "    fourv2_ghcn = fourv2_ghcn[fourv2_ghcn['metric'] == metric]\n",
    "    lead_times = fourv2_ghcn['lead_time'].values\n",
    "\n",
    "    pang_ghcn = pang_ghcn[pang_ghcn['case_id_number'] == my_case.case_id_number]\n",
    "    pang_ghcn = pang_ghcn[pang_ghcn['metric'] == metric]\n",
    "\n",
    "    hres_ghcn = hres_ghcn[hres_ghcn['case_id_number'] == my_case.case_id_number]\n",
    "    hres_ghcn = hres_ghcn[hres_ghcn['metric'] == metric]\n",
    "\n",
    "    print(\"about to do subsetting\")\n",
    "    if (forecast_hour == \"zeroz\"):\n",
    "        # extract the 0z runs\n",
    "        my_times = [idx for idx, n in enumerate(lead_times) if n.seconds % 86400 == 0]\n",
    "    elif (forecast_hour == \"twelvez\"):\n",
    "        # extract the 12z runs\n",
    "        my_times = [idx for idx, n in enumerate(lead_times) if n.seconds % 86400 == 43200]\n",
    "\n",
    "    # if forecast hour is specified, grab the runs matching those times\n",
    "    if (forecast_hour is not None):\n",
    "        fourv2_ghcn = fourv2_ghcn.iloc[my_times]\n",
    "\n",
    "        if (len(pang_ghcn) == 0):\n",
    "            print(\"No FourCastNet V2 results for this forecast hour\")\n",
    "        else:\n",
    "            pang_ghcn = pang_ghcn.iloc[my_times]\n",
    "    \n",
    "        hres_ghcn = hres_ghcn.iloc[my_times]\n",
    "\n",
    "    print(\"about to do global\")\n",
    "    # grab the global results for reference lines\n",
    "    global_fourv2_ghcn_group = global_fourv2_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_fourv2_ghcn_pivot = global_fourv2_ghcn_group[global_fourv2_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    global_pang_ghcn_group = global_pang_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_pang_ghcn_pivot = global_pang_ghcn_group[global_pang_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "\n",
    "    global_hres_ghcn_group = global_hres_ghcn[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "    global_hres_ghcn_pivot = global_hres_ghcn_group[global_hres_ghcn_group['metric']==metric].pivot(index='metric', columns='lead_time', values='value')\n",
    "    \n",
    "    if (forecast_hour == \"zeroz\"):\n",
    "        # extract the 0z runs\n",
    "        time_diff = global_fourv2_ghcn_pivot.columns.seconds % 86400 == 0\n",
    "        my_times = [idx for idx, n in enumerate(time_diff) if n]\n",
    "    elif (forecast_hour == \"twelvez\"):\n",
    "        # extract the 12z runs\n",
    "        time_diff = global_fourv2_ghcn_pivot.columns.seconds % 86400 == 43200\n",
    "        my_times = [idx for idx, n in enumerate(time_diff) if n]\n",
    "\n",
    "    if (forecast_hour is not None):\n",
    "        global_fourv2_ghcn_pivot = global_fourv2_ghcn_pivot.iloc[:, my_times]\n",
    "        global_pang_ghcn_pivot = global_pang_ghcn_pivot.iloc[:, my_times]\n",
    "        global_hres_ghcn_pivot = global_hres_ghcn_pivot.iloc[:, my_times]  \n",
    "\n",
    "    # make the plots\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(15,4))\n",
    "    fourv2_ghcn_values = fourv2_ghcn['value'].values\n",
    "    pang_ghcn_values = pang_ghcn['value'].values\n",
    "    hres_ghcn_values = hres_ghcn['value'].values\n",
    "\n",
    "    global_fourv2_ghcn_values = global_fourv2_ghcn_pivot.loc[metric].values\n",
    "    global_pang_ghcn_values = global_pang_ghcn_pivot.loc[metric].values\n",
    "    global_hres_ghcn_values = global_hres_ghcn_pivot.loc[metric].values\n",
    "\n",
    "    #print(fourv2_ghcn_values)\n",
    "\n",
    "    plt.plot(np.flip(fourv2_ghcn_values), 'r', label='FourCastNet V2 GHCN')\n",
    "    plt.plot(np.flip(global_fourv2_ghcn_values), 'r--', label='Global FourCastNet V2 GHCN')\n",
    "\n",
    "    plt.plot(np.flip(pang_ghcn_values), 'g', label='Pangu Weather GHCN')\n",
    "    plt.plot(np.flip(global_pang_ghcn_values), 'g--', label='Global Pangu Weather GHCN')\n",
    "\n",
    "    plt.plot(np.flip(hres_ghcn_values), 'm', label='HRES GHCN')\n",
    "    plt.plot(np.flip(global_hres_ghcn_values), 'm--', label='Global HRES GHCN')\n",
    "\n",
    "    # make the xticklabels more readable and show every other one\n",
    "    # print(np.arange(0, len(merged_pivot.columns), 2))\n",
    "    # print(merged_pivot.columns[::2])\n",
    "    ax.set_xticks(rotation=90, labels=np.flip(fourv2_ghcn['lead_time']), ticks=np.arange(0, len(fourv2_ghcn_values)))\n",
    "    #ax.set_xticks(ticks=np.arange(0, len(merged_pivot.columns), 2))\n",
    "\n",
    "    ax.set_ylabel('Celsius')\n",
    "    ax.set_xlabel('Initialization Time')\n",
    "    plt.title(title)\n",
    "    #ax.grid(True, which='both', axis='both', color='lightgrey', linestyle='--', linewidth=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    if (filename is not None):\n",
    "        plt.savefig(filename, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fourv2_ghcn_group = fourv2_ghcn_results[['metric', 'lead_time', 'value']].groupby(['metric', 'lead_time']).mean().reset_index()\n",
    "global_fourv2_ghcn_group[global_fourv2_ghcn_group['metric']=='rmse'].pivot(index='metric', columns='lead_time', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1e342",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_fourv2_ghcn_results['metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_case_results_by_metric(metric='rmse', title='RMSE for 0Z Case ID 31', \n",
    "                       fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results, \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       forecast_hour='zeroz', event_id=my_case.case_id_number)\n",
    "\n",
    "plot_individual_case_results_by_metric(metric='minimum_mae', title='Minimum MAE for 0Z Case ID 31', \n",
    "                       fourv2_ghcn=na_fourv2_ghcn_results, pang_ghcn=na_pang_ghcn_results, hres_ghcn=na_hres_ghcn_results, \n",
    "                       global_fourv2_ghcn=fourv2_ghcn_results, global_hres_ghcn=hres_ghcn_results, global_pang_ghcn=pang_ghcn_results,\n",
    "                       forecast_hour='zeroz', event_id=my_case.case_id_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
