{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68426dc",
   "metadata": {},
   "source": [
    "# short notebook to deal with data cleanup for Australia's hail and tornado data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b846c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports you should need for this notebook\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa941cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Date/Time UTC    datetime64[ns]\n",
      "Latitude                float64\n",
      "Longitude               float64\n",
      "Nearest town             object\n",
      "State                    object\n",
      "Hail size               float64\n",
      "report_type              object\n",
      "Fujita scale            float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14612/3044680023.py:10: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['UTC'], infer_datetime_format=True)\n",
      "/tmp/ipykernel_14612/3044680023.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['UTC'], infer_datetime_format=True)\n",
      "/tmp/ipykernel_14612/3044680023.py:24: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_tor = pd.read_csv(tor_file, delimiter=',', engine='python', parse_dates=['Date/Time UTC'], infer_datetime_format=True)\n",
      "/tmp/ipykernel_14612/3044680023.py:24: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_tor = pd.read_csv(tor_file, delimiter=',', engine='python', parse_dates=['Date/Time UTC'], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "# This only needs to be run ONCE to fix the broken datetimes in the hail and tornado data.\n",
    "# It will create new files with the fixed datetimes and a combined file for sharing.\n",
    "# If you run this again, it will overwrite the existing files, so be careful!\n",
    "\n",
    "# the combined file is uploaded to the google bucket in the ExtremeWeatherBench project\n",
    "# and can be accessed at gs://extremeweatherbench/datasets/AustralianLSRData_2020-2024.csv\n",
    "\n",
    "# fix the broken datetimes in the australian hail data\n",
    "hail_file = '/home/amy/AustralianHailData_2020-2024_cleaned.csv'\n",
    "df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['UTC'], infer_datetime_format=True)\n",
    "df_hail = df_hail[['UTC', 'Latitude', 'Longitude', 'Nearest town', 'State', \"Hail size\"]]\n",
    "# rename the date column to match the tornado data\n",
    "df_hail.rename(columns={'UTC': 'Date/Time UTC'}, inplace=True)\n",
    "\n",
    "# Crate a report_type column\n",
    "df_hail['report_type'] = 'hail'\n",
    "\n",
    "# save the new file\n",
    "new_hail_file = '/home/amy/AustralianHailData_2020-2024_cleaned_fixed.csv'\n",
    "df_hail.to_csv(new_hail_file, index=False)\n",
    "\n",
    "# fix the broken date-times in the tornado data\n",
    "tor_file = '/home/amy/AustralianTornadoData_2020-2024_cleaned.csv'\n",
    "df_tor = pd.read_csv(tor_file, delimiter=',', engine='python', parse_dates=['Date/Time UTC'], infer_datetime_format=True)\n",
    "df_tor = df_tor[['Date/Time UTC', 'Latitude', 'Longitude', 'Nearest town', 'State', \"Fujita scale\"]]\n",
    "\n",
    "# Crate a report_type column\n",
    "df_tor['report_type'] = 'tor'\n",
    "\n",
    "# save the new file\n",
    "new_tor_file = '/home/amy/AustralianTornadoData_2020-2024_cleaned_fixed.csv'\n",
    "df_tor.to_csv(new_tor_file, index=False)\n",
    "\n",
    "# create a combined file for sharing\n",
    "df_combined = pd.concat([df_hail, df_tor], ignore_index=True)\n",
    "combined_file = '/home/amy/AustralianLSRData_2020-2024.csv'\n",
    "\n",
    "# save the combined file\n",
    "df_combined.to_csv(combined_file, index=False)\n",
    "\n",
    "print (\"DONE\")\n",
    "#print the types of the dataframe\n",
    "print(df_combined.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
