{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0915e674",
   "metadata": {},
   "source": [
    "# EWB paper Figure 2: Observations \n",
    "\n",
    "We provide the exact code used to generate each figure in order to be completely reproducible and to encourage others to use EWB with their own models quickly. \n",
    "This is Figure 2, it shows all of the cases using an outline and then highlights the observations available for each inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup all the imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager\n",
    "flist = matplotlib.font_manager.get_font_names()\n",
    "from tempfile import NamedTemporaryFile\n",
    "from extremeweatherbench import evaluate, utils, cases, defaults\n",
    "import shapely\n",
    "from typing import Optional, Union, Literal\n",
    "import xarray as xr\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# make the basepath - change this to your local path\n",
    "basepath = Path.home() / 'ExtremeWeatherBench' / ''\n",
    "basepath = str(basepath) + '/'\n",
    "\n",
    "# ugly hack to load in our plotting scripts\n",
    "import sys\n",
    "sys.path.append(basepath + \"/docs/notebooks/\")\n",
    "import case_plotting as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d05c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all of the events in the yaml file\n",
    "case_dict = utils.load_events_yaml()\n",
    "\n",
    "# turn the dictionary into a list of case objects\n",
    "ewb_cases = cases.load_individual_cases(case_dict)\n",
    "\n",
    "# build out all of the expected data to evalate the case\n",
    "# this will not be a 1-1 mapping with ewb_cases because there are multiple data sources to evaluate for some cases\n",
    "# for example, a heat/cold case will have both a case operator for ERA-5 data and GHCN\n",
    "case_operators = cases.build_case_operators(case_dict, defaults.get_brightband_evaluation_objects())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc34c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from joblib.externals.loky import get_reusable_executor\n",
    "# load in all the case info (note this takes awhile in non-parallel form as it has to run all the target information for each case)\n",
    "# this will return a list of tuples with the case id and the target dataset\n",
    "\n",
    "parallel = Parallel(n_jobs=8,return_as='generator',backend='loky')\n",
    "case_operators_with_targets_established_generator = parallel(\n",
    "    delayed(lambda co: (co.case_metadata.case_id_number, evaluate.run_pipeline(co.case_metadata, co.target)))(case_operator) \n",
    "    for case_operator in case_operators\n",
    ")\n",
    "case_operators_with_targets_established = list(case_operators_with_targets_established_generator)\n",
    "# this will throw a bunch of errors below but they're not consequential. this releases the memory as it shuts down the workers\n",
    "# now that they're not used\n",
    "get_reusable_executor().shutdown(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5de1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in case_operators_with_targets_established:\n",
    "    print(target)\n",
    "    break\n",
    "len(case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c15239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the indivdual cases for each event type\n",
    "# cp.plot_all_cases_and_obs(ewb_cases, event_type='tropical_cyclone', filename='ewb_obs_tcs.png', targets=case_operators_with_targets_established)\n",
    "# cp.plot_all_cases_and_obs(ewb_cases, event_type='freeze', filename='ewb_obs_freeze.png', targets=case_operators_with_targets_established)\n",
    "# cp.plot_all_cases_and_obs(ewb_cases, event_type='heat_wave', filename='ewb_obs_heat.png', targets=case_operators_with_targets_established)\n",
    "#plot_all_cases_and_obs(ewb_cases, event_type='atmospheric_river', filename=basepath + 'docs/notebooks/figs/ewb_obs_ar.png')\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type='severe_convection', filename=basepath + 'docs/notebooks/figs/ewb_obs_convective.png', targets=case_operators_with_targets_established)\n",
    "\n",
    "# # plot all cases on one giant world map\n",
    "# plot_all_cases_and_obs(ewb_cases, event_type=None, filename=basepath + 'docs/notebooks/figs/ewb_obs_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85adeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot North America\n",
    "bot_lat = 7\n",
    "top_lat = 85\n",
    "left_lon = -172\n",
    "right_lon = -45\n",
    "\n",
    "bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "plot_title = 'ExtremeWeatherBench Cases in North America'\n",
    "\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type='severe_convection', \n",
    "    bounding_box=bounding_box, targets=case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Australia\n",
    "bot_lat = -45\n",
    "top_lat = -5\n",
    "left_lon = 105\n",
    "right_lon = 160\n",
    "bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "plot_title = 'ExtremeWeatherBench Cases in Australia'\n",
    "\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type='severe_convection', \n",
    "    bounding_box=bounding_box, targets=case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install metpy version 1.6.3 for this notebook only\n",
    "!uv pip install metpy==1.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb116c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is modified from the original code for CONUS to work with Australian LSR data\n",
    "def extract_lsr_data_australia(date: pd.Timestamp) -> pd.DataFrame:\n",
    "    \"\"\"Pull the latest LSR data for a given date. We pull all reorts within 1 day. If date is none, we return all reports\n",
    "    \n",
    "    Args:\n",
    "        date: A pandas Timestamp object.\n",
    "    Returns:\n",
    "        df: A pandas DataFrame containing the LSR data with columns lat, lon, report_type, time, and scale.\n",
    "    \"\"\"\n",
    "\n",
    "    aus_file = \"gs://extremeweatherbench/datasets/AustralianLSRData_2020-2024.csv\"\n",
    "\n",
    "    # Read the CSV files with all columns to identify report types\n",
    "    try:\n",
    "        df = pd.read_csv(aus_file, delimiter=',', engine='python', storage_options=dict(token=\"anon\"), parse_dates=['Date/Time UTC'], date_format='%Y-%m-%d %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        print(f'Error pulling hail data for {date}: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # if date is none, presumably we want all reports\n",
    "    if (date == None):\n",
    "        return df\n",
    "\n",
    "    # Filter the DataFrame for the specified date range\n",
    "    start_date = date - pd.Timedelta(days=0.5)    \n",
    "    end_date = date + pd.Timedelta(days=0.5)\n",
    "    df = df[(df['Date/Time UTC'] >= start_date) & (df['Date/Time UTC'] < end_date)]\n",
    "    if len(df) == 0:\n",
    "        print(f'No LSR data found for {date}')\n",
    "        return pd.DataFrame()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def practically_perfect_hindcast_aus(\n",
    "    date: pd.Timestamp,\n",
    "    resolution: float = 0.25,\n",
    "    report_type: Union[Literal[\"all\"], list[Literal[\"tor\", \"hail\", \"wind\"]]] = \"all\",\n",
    "    sigma: float = 1.5,\n",
    "    return_reports: bool = False,\n",
    "    output_resolution: Optional[float] = None,\n",
    "    report_constants = {'hail': 15, 'tor': 5}\n",
    ") -> Union[xr.DataArray, tuple[xr.DataArray, pd.DataFrame]]:\n",
    "    \"\"\"Compute the Practically Perfect Hindcast (PPH) using storm report data using latitude/longitude grid spacing\n",
    "    instead of the NCEP 212 Eta Lambert Conformal projection; based on the method described in Hitchens et al 2013,\n",
    "    https://doi.org/10.1175/WAF-D-12-00113.1\n",
    "\n",
    "    Args:\n",
    "        date: A pandas Timestamp object.\n",
    "        resolution: The resolution of the grid to use. Default is 0.25 degrees.\n",
    "        report_type: The type of report to use. Default is all. Currently only supports all.\n",
    "        sigma: The sigma (standard deviation) of the gaussian filter to use. Default is 1.5.\n",
    "        return_reports: Whether to return the reports used to compute the PPH. Default is False.\n",
    "        output_resolution: The resolution of the output grid. Default is None (keep the same resolution as the input grid).\n",
    "        report_constants: A dictionary mapping report types to their respective values for the PPH grid. Default is {'hail': 15, 'tor': 5}.\n",
    "    Returns:\n",
    "        pph: An xarray DataArray containing the PPH around the storm report data.\n",
    "    \"\"\"\n",
    "\n",
    "    df = extract_lsr_data_australia(date)\n",
    "    if report_type == \"all\":\n",
    "        pass\n",
    "    else:\n",
    "        df = df[df['report_type'].isin(report_type)]\n",
    "\n",
    "    # Create a grid covering Australia\n",
    "    lat_min, lat_max = -50, -10.0   \n",
    "    lon_min, lon_max = 110, 180  \n",
    "\n",
    "    # Create the grid coordinates\n",
    "    grid_lats = np.arange(lat_min, lat_max + resolution, resolution)\n",
    "    grid_lons = np.arange(lon_min, lon_max + resolution, resolution)\n",
    "\n",
    "    # Initialize an empty grid\n",
    "    grid = np.zeros((len(grid_lats), len(grid_lons)))\n",
    "\n",
    "    # extract reports for TOR and HAIL separately to handle the underreporting\n",
    "    for report_type in report_constants.keys():\n",
    "        # Filter the dataframe for the current report type\n",
    "        df2 = df[df['report_type'] == report_type]\n",
    "\n",
    "        # Extract latitude and longitude from the dataframe\n",
    "        lats = df2[\"Latitude\"].astype(float)\n",
    "        lons = df2[\"Longitude\"].astype(float)\n",
    "\n",
    "        # Mark grid cells that contain reports\n",
    "        for lat, lon in zip(lats, lons):\n",
    "            # Find the nearest grid indices\n",
    "            lat_idx = np.abs(grid_lats - lat).argmin()\n",
    "            lon_idx = np.abs(grid_lons - lon).argmin()\n",
    "            grid[lat_idx, lon_idx] = report_constants[report_type]  # Set a value to indicate a report is present\n",
    "\n",
    "    # Create the xarray DataArray\n",
    "    pph = xr.DataArray(\n",
    "        grid,\n",
    "        dims=[\"latitude\", \"longitude\"],\n",
    "        coords={\"latitude\": grid_lats, \"longitude\": grid_lons},\n",
    "        name=\"practically_perfect\",\n",
    "    )\n",
    "\n",
    "    # Apply bilinear interpolation to smooth the field\n",
    "    # First, create a gaussian kernel for smoothing\n",
    "    smoothed_grid = gaussian_filter(grid, sigma=sigma)\n",
    "\n",
    "    # Replace the data in the DataArray\n",
    "    pph.data = smoothed_grid\n",
    "    if output_resolution is not None:\n",
    "        pph = pph.interp(latitude=np.arange(lat_min, lat_max + output_resolution, output_resolution),\n",
    "                        longitude=np.arange(lon_min, lon_max + output_resolution, output_resolution),method='linear')\n",
    "        pph = pph * 100\n",
    "    if return_reports:\n",
    "        return (pph, df)\n",
    "    return pph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93530502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to pre-compute the obs info and store it in the cases\n",
    "# I think there should be either \n",
    "# 1) a quick way to grab all the metadata on the obs into the case (e.g. through a single function call at the high level) or\n",
    "# 2) it is already stored into the events yaml (just the locations, but this isn't super extensible if more obs come in later)\n",
    "# 3) a method call on each individual case to get the metadata\n",
    "# I'm going with option 3 for now\n",
    "\n",
    "# Note since there is about to be a big refactor of how events and cases are stored, this is just a temporary hack\n",
    "events_metadata = {}\n",
    "for event in cases:\n",
    "    for indiv_case in event.cases:\n",
    "        # this is what I want to see for each case\n",
    "        # commented out because it doesn't exist :) \n",
    "        # indiv_case.get_observations_metadata()\n",
    "\n",
    "        # instead I'll try to hack it\n",
    "        if (indiv_case.event_type == 'heat_wave' or indiv_case.event_type == 'freeze'):\n",
    "            # figure our how to find the obs metadata for the heat/freeze events\n",
    "            #print(\"Help, not sure how to find the obs locations\")\n",
    "            continue\n",
    "        elif (indiv_case.event_type == 'severe_convection'):\n",
    "            # grab the LSRs and compute PPH and then we can plot both the LSRs and the PPH outer outline (up in the plotting function)\n",
    "\n",
    "            # check if the case is inside the Australia bounding box\n",
    "            bot_lat = -50\n",
    "            top_lat = -10\n",
    "            left_lon = 110\n",
    "            right_lon = 180\n",
    "            bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "            bounding_box_polygon = cp.get_polygon_from_bounding_box(bounding_box)\n",
    "\n",
    "            if (shapely.intersects(indiv_case.location.geopandas.geometry[0], bounding_box_polygon)):\n",
    "                print(indiv_case)\n",
    "                \n",
    "                pph, df = practically_perfect_hindcast_aus(indiv_case.start_date, return_reports=True)\n",
    "                events_metadata[indiv_case.case_id_number] = {'pph': pph, 'lsr_reports': df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8713325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot North America\n",
    "bot_lat = 7\n",
    "top_lat = 85\n",
    "left_lon = -172\n",
    "right_lon = -45\n",
    "\n",
    "bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "plot_title = 'ExtremeWeatherBench Cases in North America'\n",
    "\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type=None, bounding_box=bounding_box, targets=case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f75bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Europe\n",
    "bot_lat = 15\n",
    "top_lat = 75\n",
    "left_lon = -15\n",
    "right_lon = 50\n",
    "\n",
    "print(right_lon, left_lon, bot_lat, top_lat)\n",
    "\n",
    "bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "plot_title = 'ExtremeWeatherBench Cases in Europe'\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type=None, bounding_box=bounding_box, targets=case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Australia\n",
    "bot_lat = -50\n",
    "top_lat = -10\n",
    "left_lon = 110\n",
    "right_lon = 180\n",
    "bounding_box = [left_lon, right_lon, bot_lat, top_lat]\n",
    "plot_title = 'ExtremeWeatherBench Cases in Australia'\n",
    "\n",
    "cp.plot_all_cases_and_obs(ewb_cases, event_type=None, bounding_box=bounding_box, targets=case_operators_with_targets_established)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441ebc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
