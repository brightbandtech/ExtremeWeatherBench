{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae34bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports you should need for this notebook\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b6388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Date/Time UTC                  datetime64[ns]\n",
      "Latitude                              float64\n",
      "Longitude                             float64\n",
      "Event Name                             object\n",
      "Minimum Hail Dimension (mm)           float64\n",
      "Maximum Hail Dimension (mm)           float64\n",
      "report_type                            object\n",
      "Event Type                             object\n",
      "Damage                                 object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2440/2335348170.py:29: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['Date & Time of Observation'], infer_datetime_format=True)\n",
      "/tmp/ipykernel_2440/2335348170.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['Date & Time of Observation'], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "# This only needs to be run ONCE to fix the broken datetimes in the hail and tornado data.\n",
    "# It will create new files with the fixed datetimes and a combined file for sharing.\n",
    "# If you run this again, it will overwrite the existing files, so be careful!\n",
    "\n",
    "# the combined file is uploaded to the google bucket in the ExtremeWeatherBench project\n",
    "# and can be accessed at gs://extremeweatherbench/datasets/AustralianLSRData_2020-2024.csv\n",
    "\n",
    "def parse_datetime(row):\n",
    "    \"\"\"\n",
    "    Parses date and time components from a DataFrame row into a single datetime object.\n",
    "    \n",
    "    Args:\n",
    "        row: A pandas Series representing a row of the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        A datetime object.\n",
    "    \"\"\"\n",
    "    # Assuming a fixed year for simplicity, adjust as needed.\n",
    "    padded_day = str(row['Day']).zfill(2)\n",
    "    padded_month = str(row['Month']).zfill(2)\n",
    "    padded_time = str(row['Time (UTC)']).zfill(4)\n",
    "    date_string = f\"{padded_month}/{padded_day}/{row['Year']} {padded_time}\"\n",
    "    #print(f\"Parsing date string: {date_string}\")  # Debugging line\n",
    "    return datetime.strptime(date_string, '%m/%d/%Y %H%M')\n",
    "\n",
    "\n",
    "# fix the broken datetimes in the australian hail data\n",
    "hail_file = \"/home/amy/NHP_edited.csv\"\n",
    "df_hail = pd.read_csv(hail_file, delimiter=',', engine='python', parse_dates=['Date & Time of Observation'], infer_datetime_format=True)\n",
    "\n",
    "# rename the date column to match the tornado data\n",
    "df_hail.rename(columns={'x': 'Longitude', 'y': 'Latitude'}, inplace=True)\n",
    "df_hail.rename(columns={'Date & Time of Observation': 'Date/Time UTC'}, inplace=True)\n",
    "df_hail = df_hail[['Date/Time UTC', 'Latitude', 'Longitude', 'Event Name', 'Minimum Hail Dimension (mm)', \"Maximum Hail Dimension (mm)\"]]\n",
    "\n",
    "# Crate a report_type column\n",
    "df_hail['report_type'] = 'hail'\n",
    "\n",
    "# save the new file\n",
    "new_hail_file = '/home/amy/NHP_2020-2024_cleaned_fixed.csv'\n",
    "df_hail.to_csv(new_hail_file, index=False)\n",
    "\n",
    "# fix the broken date-times in the tornado data\n",
    "tor_file = \"/home/amy/NTP_edited2.csv\"\n",
    "\n",
    "# parse the dates from the Day\tMonth\tTime (UTC) columns\n",
    "df_tor = pd.read_csv(tor_file, delimiter=',', engine='python')\n",
    "# Apply the function to create a new 'Datetime' column\n",
    "df_tor['Date/Time UTC'] = df_tor.apply(parse_datetime, axis=1)\n",
    "df_tor.rename(columns={'x': 'Longitude', 'y': 'Latitude'}, inplace=True)\n",
    "\n",
    "df_tor = df_tor[['Date/Time UTC', 'Latitude', 'Longitude', 'Event Name', 'Event Type', \"Damage\"]]\n",
    "\n",
    "# subselect only the torando events on the ground (no waterspouts etc)\n",
    "df_tor = df_tor[df_tor['Event Type'] == 'tornado_over_land']\n",
    "\n",
    "# Crate a report_type column\n",
    "df_tor['report_type'] = 'tor'\n",
    "\n",
    "# save the new file\n",
    "new_tor_file = '/home/amy/CanadaTor2020-2024_cleaned_fixed.csv'\n",
    "df_tor.to_csv(new_tor_file, index=False)\n",
    "\n",
    "# create a combined file for sharing\n",
    "df_combined = pd.concat([df_hail, df_tor], ignore_index=True)\n",
    "combined_file = '/home/amy/CanadaLSRData_2020-2024.csv'\n",
    "\n",
    "# save the combined file\n",
    "df_combined.to_csv(combined_file, index=False)\n",
    "\n",
    "print (\"DONE\")\n",
    "#print the types of the dataframe\n",
    "print(df_combined.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
