{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "import fsspec\n",
    "from kerchunk.hdf import SingleHdf5ToZarr \n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from pathlib import Path\n",
    "import ujson\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LongitudeFormatter, LatitudeFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scores\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import eccodes\n",
    "import dask\n",
    "import cfgrib\n",
    "import herbie.accessors\n",
    "import regionmask\n",
    "import xskillscore\n",
    "dask.config.set({'temporary_directory': '/mnt/disks/data/'})\n",
    "sns.set_theme(style='whitegrid',context='talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(\n",
    "    n_workers=8,\n",
    "    threads_per_worker=2,\n",
    "    memory_limit='5GiB',\n",
    ")\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metadata that will be available in the yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_begin = '2021-06-26 00:00'\n",
    "event_end = '2021-06-30 00:00'\n",
    "location_center = {'latitude': 47.6062, 'longitude': -122.3321}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_read = fsspec.filesystem('gcs', anon=False, skip_instance_cache=True)\n",
    "fs_local = fsspec.filesystem('')  \n",
    "json_dir = 'assets/json/'\n",
    "json_list = fs_local.glob(str(json_dir)+'PANG*_.json')\n",
    "so = dict(mode='rb', anon=True, default_fill_cache=False, default_cache_type='first')\n",
    "\n",
    "def convert_longitude_to_360(longitude):\n",
    "    return longitude % 360\n",
    "\n",
    "def generate_json_from_grap_nc(u,fs, fs_out):\n",
    "    with fs.open(u, **so) as infile:\n",
    "        h5chunks = SingleHdf5ToZarr(infile, u, inline_threshold=300)\n",
    "\n",
    "        file_split = u.split('/') # seperate file path to create a unique name for each json \n",
    "        model = file_split[1].split('_')[0]\n",
    "        date_string = file_split[-1].split('_')[3]\n",
    "        outf = f'{json_dir}{model}_{date_string}_.json'\n",
    "        print(outf)\n",
    "        with fs_out.open(outf, 'wb') as f:\n",
    "            f.write(ujson.dumps(h5chunks.translate()).encode());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intensity heat metrics\n",
    "\n",
    "def threshold_weighted_rmse(da_fcst: xr.DataArray, da_obs: xr.DataArray, threshold: float, threshold_tolerance: float):\n",
    "    mse = scores.continuous.tw_squared_error(da_fcst, \n",
    "                                             da_obs, \n",
    "                                             interval_where_one=(threshold, np.inf), \n",
    "                                             interval_where_positive=(threshold-threshold_tolerance, np.inf)\n",
    "                                             )\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def mae_max_of_max_temperatures(da_fcst: xr.DataArray, da_obs: xr.DataArray):\n",
    "    mae = scores.continuous.mae(da_fcst.groupby('time.day').max().max(dim='time'),\n",
    "                                da_obs.groupby('time.day').max().max(dim='time'))\n",
    "    return mae\n",
    "\n",
    "def mae_max_of_min_temperatures(da_fcst: xr.DataArray, da_obs: xr.DataArray):\n",
    "    mae = scores.continuous.mae(da_fcst.groupby('time.day').min().max(dim='time'),\n",
    "                                da_obs.groupby('time.day').min().max(dim='time'))\n",
    "    return mae\n",
    "\n",
    "\n",
    "#Duration heat metrics\n",
    "def onset_above_85th_percentile(da_fcst: xr.DataArray, da_obs: xr.DataArray, da_clim_85th: xr.DataArray):\n",
    "    def first_above_threshold(da, threshold):\n",
    "        above_threshold = da > threshold\n",
    "        first_time = above_threshold.argmax(dim='time')\n",
    "        return first_time\n",
    "\n",
    "    fcst_first_above = first_above_threshold(da_fcst, da_clim_85th)\n",
    "    obs_first_above = first_above_threshold(da_obs, da_clim_85th)\n",
    "    \n",
    "    onset_me = (fcst_first_above - obs_first_above).astype(float)\n",
    "    onset_me_hours = onset_me * np.timedelta64(1, 'h')\n",
    "    return onset_me_hours\n",
    "\n",
    "def mae_onset_and_end_above_85th_percentile(da_fcst: xr.DataArray, da_obs: xr.DataArray, da_clim_85th: xr.DataArray):\n",
    "    def first_and_last_above_threshold(da, threshold):\n",
    "        above_threshold = da > threshold\n",
    "        first_time = above_threshold.argmax(dim='time')\n",
    "        last_time = len(da['time']) - above_threshold[::-1].argmax(dim='time') - 1\n",
    "        return first_time, last_time\n",
    "\n",
    "    fcst_first_above, fcst_last_above = first_and_last_above_threshold(da_fcst, da_clim_85th)\n",
    "    obs_first_above, obs_last_above = first_and_last_above_threshold(da_obs, da_clim_85th)\n",
    "    \n",
    "    onset_mae = np.abs(fcst_first_above - obs_first_above).astype(float)\n",
    "    end_mae = np.abs(fcst_last_above - obs_last_above).astype(float)\n",
    "    \n",
    "    mean_absolute_error = ((onset_mae + end_mae) / 2) * np.timedelta64(1, 'h')\n",
    "    return mean_absolute_error\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
